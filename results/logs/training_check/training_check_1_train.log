Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 94 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 79 training files, 15 validation files.
Training dataset size: 83381, Validation dataset size: 15362
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/1303 | Train Loss: 0.3289 (P: 0.3198 V: 0.2765 A: 0.4844 B: 0.0906)
Epoch 1 | Batch 50/1303 | Train Loss: 0.2304 (P: 0.2304 V: 0.1042 A: 0.1799 B: 0.0000)
Epoch 1 | Batch 100/1303 | Train Loss: 0.2238 (P: 0.2238 V: 0.0919 A: 0.1591 B: 0.0000)
Epoch 1 | Batch 150/1303 | Train Loss: 0.2143 (P: 0.2143 V: 0.0770 A: 0.1317 B: 0.0000)
Epoch 1 | Batch 200/1303 | Train Loss: 0.2097 (P: 0.2097 V: 0.0679 A: 0.1168 B: 0.0000)
Epoch 1 | Batch 250/1303 | Train Loss: 0.2110 (P: 0.2110 V: 0.0604 A: 0.1048 B: 0.0000)
Epoch 1 | Batch 300/1303 | Train Loss: 0.2104 (P: 0.2104 V: 0.0541 A: 0.0935 B: 0.0000)
Epoch 1 | Batch 350/1303 | Train Loss: 0.2096 (P: 0.2096 V: 0.0516 A: 0.0889 B: 0.0000)
Epoch 1 | Batch 400/1303 | Train Loss: 0.2065 (P: 0.2065 V: 0.0453 A: 0.0782 B: 0.0000)
Epoch 1 | Batch 450/1303 | Train Loss: 0.2066 (P: 0.2066 V: 0.0413 A: 0.0710 B: 0.0000)
Epoch 1 | Batch 500/1303 | Train Loss: 0.2037 (P: 0.2037 V: 0.0399 A: 0.0690 B: 0.0000)
Epoch 1 | Batch 550/1303 | Train Loss: 0.2045 (P: 0.2045 V: 0.0365 A: 0.0629 B: 0.0000)
Epoch 1 | Batch 600/1303 | Train Loss: 0.2027 (P: 0.2027 V: 0.0349 A: 0.0608 B: 0.0000)
Epoch 1 | Batch 650/1303 | Train Loss: 0.2051 (P: 0.2051 V: 0.0326 A: 0.0568 B: 0.0000)
Epoch 1 | Batch 700/1303 | Train Loss: 0.1993 (P: 0.1993 V: 0.0320 A: 0.0552 B: 0.0000)
Epoch 1 | Batch 750/1303 | Train Loss: 0.2048 (P: 0.2048 V: 0.0305 A: 0.0527 B: 0.0000)
Epoch 1 | Batch 800/1303 | Train Loss: 0.2052 (P: 0.2052 V: 0.0297 A: 0.0512 B: 0.0000)
Epoch 1 | Batch 850/1303 | Train Loss: 0.2052 (P: 0.2052 V: 0.0283 A: 0.0488 B: 0.0000)
Epoch 1 | Batch 900/1303 | Train Loss: 0.1960 (P: 0.1960 V: 0.0279 A: 0.0480 B: 0.0000)
Epoch 1 | Batch 950/1303 | Train Loss: 0.1976 (P: 0.1976 V: 0.0265 A: 0.0455 B: 0.0000)
Epoch 1 | Batch 1000/1303 | Train Loss: 0.2075 (P: 0.2075 V: 0.0255 A: 0.0434 B: 0.0000)
Epoch 1 | Batch 1050/1303 | Train Loss: 0.2019 (P: 0.2019 V: 0.0259 A: 0.0448 B: 0.0000)
Epoch 1 | Batch 1100/1303 | Train Loss: 0.2048 (P: 0.2048 V: 0.0243 A: 0.0416 B: 0.0000)
Epoch 1 | Batch 1150/1303 | Train Loss: 0.2041 (P: 0.2041 V: 0.0241 A: 0.0411 B: 0.0000)
Epoch 1 | Batch 1200/1303 | Train Loss: 0.2011 (P: 0.2011 V: 0.0234 A: 0.0401 B: 0.0000)
Epoch 1 | Batch 1250/1303 | Train Loss: 0.1970 (P: 0.1970 V: 0.0222 A: 0.0382 B: 0.0000)
Epoch 1 | Batch 1300/1303 | Train Loss: 0.2000 (P: 0.2000 V: 0.0224 A: 0.0386 B: 0.0000)
Epoch 1/1 | Avg Train Loss: 0.2138 (P: 0.2138 V: 0.0436 A: 0.0753 B: 0.0001)
Epoch 1 | Val Loss: 0.2016 MPJPE: 2663.77mm (P: 0.2016 V: 0.0023 A: 0.0014 B: 0.0000)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_001_valloss_0.2016_mpjpe_2663.77_B_0.0000.pth
Training finished for run: training_check_1
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 94 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 79 training files, 15 validation files.
Training dataset size: 83381, Validation dataset size: 15362
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/1303 | Train Loss: 0.4791 (P: 0.4730 V: 0.2553 A: 0.4385 B: 0.0607)
Epoch 1 | Batch 50/1303 | Train Loss: 0.2276 (P: 0.2276 V: 0.1080 A: 0.1870 B: 0.0000)
Epoch 1 | Batch 100/1303 | Train Loss: 0.2147 (P: 0.2147 V: 0.0865 A: 0.1500 B: 0.0000)
Epoch 1 | Batch 150/1303 | Train Loss: 0.2257 (P: 0.2257 V: 0.0724 A: 0.1255 B: 0.0000)
Epoch 1 | Batch 200/1303 | Train Loss: 0.2154 (P: 0.2154 V: 0.0675 A: 0.1174 B: 0.0000)
Epoch 1 | Batch 250/1303 | Train Loss: 0.2071 (P: 0.2071 V: 0.0600 A: 0.1040 B: 0.0000)
Epoch 1 | Batch 300/1303 | Train Loss: 0.2026 (P: 0.2026 V: 0.0537 A: 0.0919 B: 0.0000)
Epoch 1 | Batch 350/1303 | Train Loss: 0.2037 (P: 0.2037 V: 0.0478 A: 0.0830 B: 0.0000)
Epoch 1 | Batch 400/1303 | Train Loss: 0.2020 (P: 0.2020 V: 0.0439 A: 0.0753 B: 0.0000)
Epoch 1 | Batch 450/1303 | Train Loss: 0.1988 (P: 0.1988 V: 0.0415 A: 0.0711 B: 0.0000)
Epoch 1 | Batch 500/1303 | Train Loss: 0.2112 (P: 0.2112 V: 0.0399 A: 0.0691 B: 0.0000)
Epoch 1 | Batch 550/1303 | Train Loss: 0.2010 (P: 0.2010 V: 0.0384 A: 0.0663 B: 0.0000)
Epoch 1 | Batch 600/1303 | Train Loss: 0.2026 (P: 0.2026 V: 0.0356 A: 0.0609 B: 0.0000)
Epoch 1 | Batch 650/1303 | Train Loss: 0.1990 (P: 0.1990 V: 0.0345 A: 0.0599 B: 0.0000)
Epoch 1 | Batch 700/1303 | Train Loss: 0.2054 (P: 0.2054 V: 0.0326 A: 0.0560 B: 0.0000)
Epoch 1 | Batch 750/1303 | Train Loss: 0.1988 (P: 0.1988 V: 0.0310 A: 0.0531 B: 0.0000)
Epoch 1 | Batch 800/1303 | Train Loss: 0.2001 (P: 0.2001 V: 0.0293 A: 0.0506 B: 0.0000)
Epoch 1 | Batch 850/1303 | Train Loss: 0.1991 (P: 0.1991 V: 0.0265 A: 0.0454 B: 0.0000)
Epoch 1 | Batch 900/1303 | Train Loss: 0.2001 (P: 0.2001 V: 0.0266 A: 0.0456 B: 0.0000)
Epoch 1 | Batch 950/1303 | Train Loss: 0.1981 (P: 0.1981 V: 0.0247 A: 0.0421 B: 0.0000)
Epoch 1 | Batch 1000/1303 | Train Loss: 0.1981 (P: 0.1981 V: 0.0231 A: 0.0394 B: 0.0000)
Epoch 1 | Batch 1050/1303 | Train Loss: 0.2000 (P: 0.2000 V: 0.0222 A: 0.0380 B: 0.0000)
Epoch 1 | Batch 1100/1303 | Train Loss: 0.1966 (P: 0.1966 V: 0.0220 A: 0.0377 B: 0.0000)
Epoch 1 | Batch 1150/1303 | Train Loss: 0.1969 (P: 0.1969 V: 0.0214 A: 0.0366 B: 0.0000)
Epoch 1 | Batch 1200/1303 | Train Loss: 0.1987 (P: 0.1987 V: 0.0207 A: 0.0355 B: 0.0000)
Epoch 1 | Batch 1250/1303 | Train Loss: 0.1956 (P: 0.1956 V: 0.0195 A: 0.0335 B: 0.0000)
Epoch 1 | Batch 1300/1303 | Train Loss: 0.1981 (P: 0.1981 V: 0.0188 A: 0.0322 B: 0.0000)
Epoch 1/1 | Avg Train Loss: 0.2137 (P: 0.2137 V: 0.0424 A: 0.0731 B: 0.0004)
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 94 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 79 training files, 15 validation files.
Training dataset size: 83381, Validation dataset size: 15362
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/1303 | Train Loss: 0.6431 (P: 0.6330 V: 0.2546 A: 0.4266 B: 0.1013)
Epoch 1 | Batch 50/1303 | Train Loss: 0.2352 (P: 0.2352 V: 0.1040 A: 0.1810 B: 0.0000)
Epoch 1 | Batch 100/1303 | Train Loss: 0.2159 (P: 0.2159 V: 0.0833 A: 0.1438 B: 0.0000)
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 94 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 79 training files, 15 validation files.
Training dataset size: 83381, Validation dataset size: 15362
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/1303 | Train Loss: 0.3641 (P: 0.3446 V: 0.2582 A: 0.4496 B: 0.1952)
Epoch 1 | Batch 50/1303 | Train Loss: 0.2254 (P: 0.2254 V: 0.1083 A: 0.1867 B: 0.0000)
Epoch 1 | Batch 100/1303 | Train Loss: 0.2193 (P: 0.2193 V: 0.0873 A: 0.1493 B: 0.0000)
Epoch 1 | Batch 150/1303 | Train Loss: 0.2108 (P: 0.2108 V: 0.0776 A: 0.1341 B: 0.0000)
Epoch 1 | Batch 200/1303 | Train Loss: 0.2101 (P: 0.2101 V: 0.0713 A: 0.1227 B: 0.0000)
Epoch 1 | Batch 250/1303 | Train Loss: 0.2054 (P: 0.2054 V: 0.0605 A: 0.1047 B: 0.0000)
Epoch 1 | Batch 300/1303 | Train Loss: 0.2098 (P: 0.2098 V: 0.0533 A: 0.0919 B: 0.0000)
Epoch 1 | Batch 350/1303 | Train Loss: 0.2077 (P: 0.2077 V: 0.0477 A: 0.0823 B: 0.0000)
Epoch 1 | Batch 400/1303 | Train Loss: 0.2044 (P: 0.2044 V: 0.0428 A: 0.0740 B: 0.0000)
Epoch 1 | Batch 450/1303 | Train Loss: 0.2014 (P: 0.2014 V: 0.0393 A: 0.0678 B: 0.0000)
Epoch 1 | Batch 500/1303 | Train Loss: 0.2036 (P: 0.2036 V: 0.0369 A: 0.0638 B: 0.0000)
Epoch 1 | Batch 550/1303 | Train Loss: 0.2047 (P: 0.2047 V: 0.0349 A: 0.0603 B: 0.0000)
Epoch 1 | Batch 600/1303 | Train Loss: 0.2035 (P: 0.2035 V: 0.0334 A: 0.0577 B: 0.0000)
Epoch 1 | Batch 650/1303 | Train Loss: 0.2034 (P: 0.2034 V: 0.0321 A: 0.0557 B: 0.0000)
Epoch 1 | Batch 700/1303 | Train Loss: 0.1972 (P: 0.1972 V: 0.0299 A: 0.0515 B: 0.0000)
Epoch 1 | Batch 750/1303 | Train Loss: 0.1969 (P: 0.1969 V: 0.0283 A: 0.0490 B: 0.0000)
Epoch 1 | Batch 800/1303 | Train Loss: 0.2001 (P: 0.2001 V: 0.0274 A: 0.0471 B: 0.0000)
Epoch 1 | Batch 850/1303 | Train Loss: 0.1999 (P: 0.1999 V: 0.0261 A: 0.0452 B: 0.0000)
Epoch 1 | Batch 900/1303 | Train Loss: 0.1989 (P: 0.1989 V: 0.0246 A: 0.0422 B: 0.0000)
Epoch 1 | Batch 950/1303 | Train Loss: 0.2008 (P: 0.2008 V: 0.0246 A: 0.0422 B: 0.0000)
Epoch 1 | Batch 1000/1303 | Train Loss: 0.1998 (P: 0.1998 V: 0.0231 A: 0.0396 B: 0.0000)
Epoch 1 | Batch 1050/1303 | Train Loss: 0.1987 (P: 0.1987 V: 0.0219 A: 0.0373 B: 0.0000)
Epoch 1 | Batch 1100/1303 | Train Loss: 0.1998 (P: 0.1998 V: 0.0215 A: 0.0368 B: 0.0000)
Epoch 1 | Batch 1150/1303 | Train Loss: 0.2004 (P: 0.2004 V: 0.0220 A: 0.0376 B: 0.0000)
Epoch 1 | Batch 1200/1303 | Train Loss: 0.1977 (P: 0.1977 V: 0.0204 A: 0.0351 B: 0.0000)
Epoch 1 | Batch 1250/1303 | Train Loss: 0.1976 (P: 0.1976 V: 0.0198 A: 0.0339 B: 0.0000)
Epoch 1 | Batch 1300/1303 | Train Loss: 0.1948 (P: 0.1948 V: 0.0194 A: 0.0332 B: 0.0000)
Epoch 1/1 | Avg Train Loss: 0.2143 (P: 0.2142 V: 0.0417 A: 0.0719 B: 0.0005)
Epoch 1 | Val Loss: 0.2011 MPJPE: 449.15mm (P: 0.2011 V: 0.0022 A: 0.0011 B: 0.0000)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_001_valloss_0.2011_mpjpe_449.15_B_0.0000.pth
Training finished for run: training_check_1
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 21 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 17 training files, 4 validation files.
Error: Training dataset is empty. Exiting.
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 21 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 17 training files, 4 validation files.
Error: Training dataset is empty. Exiting.
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 41 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 34 training files, 7 validation files.
Training dataset size: 58587, Validation dataset size: 15076
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/916 | Train Loss: 0.7443 (P: 0.7358 V: 0.4785 A: 0.8195 B: 0.0846)
Epoch 1 | Batch 50/916 | Train Loss: 0.2207 (P: 0.2152 V: 0.1115 A: 0.1939 B: 0.0553)
Epoch 1 | Batch 100/916 | Train Loss: 0.2077 (P: 0.2020 V: 0.0967 A: 0.1678 B: 0.0570)
Epoch 1 | Batch 150/916 | Train Loss: 0.2004 (P: 0.1949 V: 0.0818 A: 0.1407 B: 0.0553)
Epoch 1 | Batch 200/916 | Train Loss: 0.1756 (P: 0.1692 V: 0.0847 A: 0.1469 B: 0.0644)
Epoch 1 | Batch 250/916 | Train Loss: 0.1499 (P: 0.1452 V: 0.0761 A: 0.1317 B: 0.0471)
Epoch 1 | Batch 300/916 | Train Loss: 0.1402 (P: 0.1351 V: 0.0688 A: 0.1193 B: 0.0502)
Epoch 1 | Batch 350/916 | Train Loss: 0.1341 (P: 0.1289 V: 0.0653 A: 0.1130 B: 0.0520)
Epoch 1 | Batch 400/916 | Train Loss: 0.1326 (P: 0.1278 V: 0.0605 A: 0.1047 B: 0.0481)
Epoch 1 | Batch 450/916 | Train Loss: 0.1330 (P: 0.1276 V: 0.0545 A: 0.0943 B: 0.0535)
Epoch 1 | Batch 500/916 | Train Loss: 0.1288 (P: 0.1238 V: 0.0542 A: 0.0940 B: 0.0500)
Epoch 1 | Batch 550/916 | Train Loss: 0.1305 (P: 0.1257 V: 0.0507 A: 0.0877 B: 0.0474)
Epoch 1 | Batch 600/916 | Train Loss: 0.1193 (P: 0.1141 V: 0.0509 A: 0.0880 B: 0.0515)
Epoch 1 | Batch 650/916 | Train Loss: 0.1163 (P: 0.1108 V: 0.0483 A: 0.0826 B: 0.0549)
Epoch 1 | Batch 700/916 | Train Loss: 0.1106 (P: 0.1052 V: 0.0455 A: 0.0785 B: 0.0540)
Epoch 1 | Batch 750/916 | Train Loss: 0.1098 (P: 0.1046 V: 0.0449 A: 0.0779 B: 0.0524)
Epoch 1 | Batch 800/916 | Train Loss: 0.1073 (P: 0.1021 V: 0.0417 A: 0.0719 B: 0.0517)
Epoch 1 | Batch 850/916 | Train Loss: 0.1070 (P: 0.1017 V: 0.0409 A: 0.0706 B: 0.0529)
Epoch 1 | Batch 900/916 | Train Loss: 0.1063 (P: 0.1011 V: 0.0383 A: 0.0662 B: 0.0526)
Epoch 1/1 | Avg Train Loss: 0.1489 (P: 0.1436 V: 0.0655 A: 0.1133 B: 0.0532)
Epoch 1 | Val Loss: 0.0984 MPJPE: 195.25mm (P: 0.0933 V: 0.0026 A: 0.0029 B: 0.0510)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_001_valloss_0.0984_mpjpe_195.25_B_0.0510.pth
Training finished for run: training_check_1
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.5, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 41 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 34 training files, 7 validation files.
Training dataset size: 58587, Validation dataset size: 15076
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/916 | Train Loss: 0.9481 (P: 0.8679 V: 0.5935 A: 1.0218 B: 0.1605)
Epoch 1 | Batch 50/916 | Train Loss: 0.2161 (P: 0.1873 V: 0.1161 A: 0.2000 B: 0.0577)
Epoch 1 | Batch 100/916 | Train Loss: 0.1956 (P: 0.1711 V: 0.0988 A: 0.1712 B: 0.0490)
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 10, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.5, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 41 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 34 training files, 7 validation files.
Training dataset size: 58587, Validation dataset size: 15076
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/916 | Train Loss: 0.6932 (P: 0.6031 V: 0.6041 A: 1.0299 B: 0.1802)
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 10, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.5, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 41 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 34 training files, 7 validation files.
Training dataset size: 58587, Validation dataset size: 15076
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/916 | Train Loss: 0.9572 (P: 0.7840 V: 0.8106 A: 1.3933 B: 0.3463)
Epoch 1 | Batch 50/916 | Train Loss: 0.1623 (P: 0.1607 V: 0.1171 A: 0.2039 B: 0.0031)
Epoch 1 | Batch 100/916 | Train Loss: 0.1550 (P: 0.1540 V: 0.1015 A: 0.1754 B: 0.0020)
Epoch 1 | Batch 150/916 | Train Loss: 0.1299 (P: 0.1287 V: 0.0942 A: 0.1633 B: 0.0024)
Epoch 1 | Batch 200/916 | Train Loss: 0.1060 (P: 0.1047 V: 0.0846 A: 0.1469 B: 0.0026)
Epoch 1 | Batch 250/916 | Train Loss: 0.0867 (P: 0.0854 V: 0.0782 A: 0.1355 B: 0.0026)
Epoch 1 | Batch 300/916 | Train Loss: 0.0799 (P: 0.0784 V: 0.0713 A: 0.1234 B: 0.0028)
Epoch 1 | Batch 350/916 | Train Loss: 0.0820 (P: 0.0806 V: 0.0683 A: 0.1184 B: 0.0027)
Epoch 1 | Batch 400/916 | Train Loss: 0.0866 (P: 0.0850 V: 0.0622 A: 0.1076 B: 0.0031)
Epoch 1 | Batch 450/916 | Train Loss: 0.0740 (P: 0.0726 V: 0.0607 A: 0.1050 B: 0.0029)
Epoch 1 | Batch 500/916 | Train Loss: 0.0814 (P: 0.0800 V: 0.0556 A: 0.0961 B: 0.0028)
Epoch 1 | Batch 550/916 | Train Loss: 0.0821 (P: 0.0807 V: 0.0539 A: 0.0934 B: 0.0028)
Epoch 1 | Batch 600/916 | Train Loss: 0.0773 (P: 0.0759 V: 0.0521 A: 0.0902 B: 0.0028)
Epoch 1 | Batch 650/916 | Train Loss: 0.0699 (P: 0.0684 V: 0.0507 A: 0.0878 B: 0.0029)
Epoch 1 | Batch 700/916 | Train Loss: 0.0611 (P: 0.0596 V: 0.0494 A: 0.0851 B: 0.0030)
Epoch 1 | Batch 750/916 | Train Loss: 0.0564 (P: 0.0549 V: 0.0463 A: 0.0801 B: 0.0031)
Epoch 1 | Batch 800/916 | Train Loss: 0.0630 (P: 0.0615 V: 0.0454 A: 0.0782 B: 0.0029)
Epoch 1 | Batch 850/916 | Train Loss: 0.0600 (P: 0.0584 V: 0.0443 A: 0.0764 B: 0.0030)
Epoch 1 | Batch 900/916 | Train Loss: 0.0557 (P: 0.0541 V: 0.0428 A: 0.0736 B: 0.0031)
Epoch 1/10 | Avg Train Loss: 0.0989 (P: 0.0965 V: 0.0698 A: 0.1207 B: 0.0048)
Epoch 1 | Val Loss: 0.0533 MPJPE: 103.55mm (P: 0.0517 V: 0.0032 A: 0.0042 B: 0.0032)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_001_valloss_0.0533_mpjpe_103.55_B_0.0032.pth
Epoch 2 | Batch 0/916 | Train Loss: 0.0587 (P: 0.0571 V: 0.0420 A: 0.0728 B: 0.0031)
Epoch 2 | Batch 50/916 | Train Loss: 0.0633 (P: 0.0618 V: 0.0401 A: 0.0695 B: 0.0030)
Epoch 2 | Batch 100/916 | Train Loss: 0.0563 (P: 0.0547 V: 0.0404 A: 0.0698 B: 0.0032)
Epoch 2 | Batch 150/916 | Train Loss: 0.0507 (P: 0.0492 V: 0.0387 A: 0.0667 B: 0.0030)
Epoch 2 | Batch 200/916 | Train Loss: 0.0496 (P: 0.0480 V: 0.0376 A: 0.0649 B: 0.0031)
Epoch 2 | Batch 250/916 | Train Loss: 0.0512 (P: 0.0495 V: 0.0366 A: 0.0631 B: 0.0034)
Epoch 2 | Batch 300/916 | Train Loss: 0.0488 (P: 0.0471 V: 0.0363 A: 0.0630 B: 0.0034)
Epoch 2 | Batch 350/916 | Train Loss: 0.0534 (P: 0.0518 V: 0.0356 A: 0.0615 B: 0.0032)
Epoch 2 | Batch 400/916 | Train Loss: 0.0523 (P: 0.0507 V: 0.0350 A: 0.0603 B: 0.0033)
Epoch 2 | Batch 450/916 | Train Loss: 0.0486 (P: 0.0470 V: 0.0348 A: 0.0600 B: 0.0032)
Epoch 2 | Batch 500/916 | Train Loss: 0.0568 (P: 0.0552 V: 0.0337 A: 0.0580 B: 0.0033)
Epoch 2 | Batch 550/916 | Train Loss: 0.0445 (P: 0.0429 V: 0.0325 A: 0.0561 B: 0.0032)
Epoch 2 | Batch 600/916 | Train Loss: 0.0481 (P: 0.0464 V: 0.0317 A: 0.0546 B: 0.0034)
Epoch 2 | Batch 650/916 | Train Loss: 0.0443 (P: 0.0427 V: 0.0311 A: 0.0536 B: 0.0032)
Epoch 2 | Batch 700/916 | Train Loss: 0.0426 (P: 0.0410 V: 0.0307 A: 0.0532 B: 0.0033)
Epoch 2 | Batch 750/916 | Train Loss: 0.0522 (P: 0.0506 V: 0.0302 A: 0.0519 B: 0.0032)
Epoch 2 | Batch 800/916 | Train Loss: 0.0466 (P: 0.0449 V: 0.0302 A: 0.0520 B: 0.0033)
Epoch 2 | Batch 850/916 | Train Loss: 0.0443 (P: 0.0426 V: 0.0295 A: 0.0509 B: 0.0033)
Epoch 2 | Batch 900/916 | Train Loss: 0.0427 (P: 0.0411 V: 0.0284 A: 0.0492 B: 0.0033)
Epoch 2/10 | Avg Train Loss: 0.0510 (P: 0.0494 V: 0.0344 A: 0.0594 B: 0.0032)
Epoch 2 | Val Loss: 0.0459 MPJPE: 89.12mm (P: 0.0442 V: 0.0025 A: 0.0028 B: 0.0034)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_002_valloss_0.0459_mpjpe_89.12_B_0.0034.pth
Epoch 3 | Batch 0/916 | Train Loss: 0.0500 (P: 0.0483 V: 0.0287 A: 0.0496 B: 0.0034)
Epoch 3 | Batch 50/916 | Train Loss: 0.0463 (P: 0.0447 V: 0.0286 A: 0.0494 B: 0.0033)
Epoch 3 | Batch 100/916 | Train Loss: 0.0462 (P: 0.0445 V: 0.0283 A: 0.0488 B: 0.0033)
Epoch 3 | Batch 150/916 | Train Loss: 0.0491 (P: 0.0474 V: 0.0280 A: 0.0483 B: 0.0034)
Epoch 3 | Batch 200/916 | Train Loss: 0.0394 (P: 0.0378 V: 0.0277 A: 0.0479 B: 0.0033)
Epoch 3 | Batch 250/916 | Train Loss: 0.0465 (P: 0.0449 V: 0.0273 A: 0.0472 B: 0.0032)
Epoch 3 | Batch 300/916 | Train Loss: 0.0384 (P: 0.0367 V: 0.0267 A: 0.0460 B: 0.0034)
Epoch 3 | Batch 350/916 | Train Loss: 0.0400 (P: 0.0382 V: 0.0271 A: 0.0468 B: 0.0036)
Epoch 3 | Batch 400/916 | Train Loss: 0.0419 (P: 0.0402 V: 0.0262 A: 0.0452 B: 0.0034)
Epoch 3 | Batch 450/916 | Train Loss: 0.0400 (P: 0.0384 V: 0.0259 A: 0.0449 B: 0.0032)
Epoch 3 | Batch 500/916 | Train Loss: 0.0396 (P: 0.0380 V: 0.0257 A: 0.0444 B: 0.0033)
Epoch 3 | Batch 550/916 | Train Loss: 0.0373 (P: 0.0357 V: 0.0254 A: 0.0439 B: 0.0033)
Epoch 3 | Batch 600/916 | Train Loss: 0.0447 (P: 0.0429 V: 0.0261 A: 0.0451 B: 0.0036)
Epoch 3 | Batch 650/916 | Train Loss: 0.0405 (P: 0.0388 V: 0.0253 A: 0.0437 B: 0.0033)
Epoch 3 | Batch 700/916 | Train Loss: 0.0384 (P: 0.0367 V: 0.0249 A: 0.0429 B: 0.0034)
Epoch 3 | Batch 750/916 | Train Loss: 0.0341 (P: 0.0324 V: 0.0248 A: 0.0431 B: 0.0034)
Epoch 3 | Batch 800/916 | Train Loss: 0.0388 (P: 0.0371 V: 0.0241 A: 0.0416 B: 0.0035)
Epoch 3 | Batch 850/916 | Train Loss: 0.0363 (P: 0.0345 V: 0.0236 A: 0.0407 B: 0.0036)
Epoch 3 | Batch 900/916 | Train Loss: 0.0370 (P: 0.0354 V: 0.0234 A: 0.0406 B: 0.0032)
Epoch 3/10 | Avg Train Loss: 0.0412 (P: 0.0396 V: 0.0261 A: 0.0450 B: 0.0033)
Epoch 3 | Val Loss: 0.0382 MPJPE: 73.35mm (P: 0.0365 V: 0.0019 A: 0.0022 B: 0.0034)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_003_valloss_0.0382_mpjpe_73.35_B_0.0034.pth
Epoch 4 | Batch 0/916 | Train Loss: 0.0389 (P: 0.0372 V: 0.0245 A: 0.0423 B: 0.0034)
Epoch 4 | Batch 50/916 | Train Loss: 0.0373 (P: 0.0355 V: 0.0237 A: 0.0409 B: 0.0036)
Epoch 4 | Batch 100/916 | Train Loss: 0.0349 (P: 0.0332 V: 0.0235 A: 0.0406 B: 0.0033)
Epoch 4 | Batch 150/916 | Train Loss: 0.0349 (P: 0.0332 V: 0.0221 A: 0.0380 B: 0.0035)
Epoch 4 | Batch 200/916 | Train Loss: 0.0356 (P: 0.0339 V: 0.0229 A: 0.0395 B: 0.0034)
Epoch 4 | Batch 250/916 | Train Loss: 0.0333 (P: 0.0315 V: 0.0221 A: 0.0380 B: 0.0036)
Epoch 4 | Batch 300/916 | Train Loss: 0.0333 (P: 0.0315 V: 0.0220 A: 0.0380 B: 0.0036)
Epoch 4 | Batch 350/916 | Train Loss: 0.0346 (P: 0.0329 V: 0.0222 A: 0.0382 B: 0.0034)
Epoch 4 | Batch 400/916 | Train Loss: 0.0337 (P: 0.0319 V: 0.0217 A: 0.0375 B: 0.0037)
Epoch 4 | Batch 450/916 | Train Loss: 0.0320 (P: 0.0302 V: 0.0218 A: 0.0377 B: 0.0037)
Epoch 4 | Batch 500/916 | Train Loss: 0.0399 (P: 0.0382 V: 0.0219 A: 0.0380 B: 0.0034)
Epoch 4 | Batch 550/916 | Train Loss: 0.0379 (P: 0.0364 V: 0.0220 A: 0.0377 B: 0.0031)
Epoch 4 | Batch 600/916 | Train Loss: 0.0394 (P: 0.0377 V: 0.0215 A: 0.0371 B: 0.0034)
Epoch 4 | Batch 650/916 | Train Loss: 0.0317 (P: 0.0299 V: 0.0209 A: 0.0363 B: 0.0036)
Epoch 4 | Batch 700/916 | Train Loss: 0.0413 (P: 0.0395 V: 0.0209 A: 0.0360 B: 0.0036)
Epoch 4 | Batch 750/916 | Train Loss: 0.0353 (P: 0.0335 V: 0.0209 A: 0.0360 B: 0.0036)
Epoch 4 | Batch 800/916 | Train Loss: 0.0356 (P: 0.0340 V: 0.0200 A: 0.0344 B: 0.0033)
Epoch 4 | Batch 850/916 | Train Loss: 0.0326 (P: 0.0308 V: 0.0200 A: 0.0344 B: 0.0036)
Epoch 4 | Batch 900/916 | Train Loss: 0.0299 (P: 0.0281 V: 0.0198 A: 0.0342 B: 0.0035)
Epoch 4/10 | Avg Train Loss: 0.0348 (P: 0.0331 V: 0.0216 A: 0.0372 B: 0.0035)
Epoch 4 | Val Loss: 0.0310 MPJPE: 58.82mm (P: 0.0291 V: 0.0016 A: 0.0017 B: 0.0037)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_004_valloss_0.0310_mpjpe_58.82_B_0.0037.pth
Epoch 5 | Batch 0/916 | Train Loss: 0.0300 (P: 0.0282 V: 0.0192 A: 0.0330 B: 0.0036)
Epoch 5 | Batch 50/916 | Train Loss: 0.0295 (P: 0.0277 V: 0.0193 A: 0.0333 B: 0.0036)
Epoch 5 | Batch 100/916 | Train Loss: 0.0329 (P: 0.0312 V: 0.0195 A: 0.0337 B: 0.0034)
Epoch 5 | Batch 150/916 | Train Loss: 0.0409 (P: 0.0392 V: 0.0196 A: 0.0340 B: 0.0034)
Epoch 5 | Batch 200/916 | Train Loss: 0.0312 (P: 0.0296 V: 0.0199 A: 0.0343 B: 0.0032)
Epoch 5 | Batch 250/916 | Train Loss: 0.0322 (P: 0.0305 V: 0.0196 A: 0.0338 B: 0.0035)
Epoch 5 | Batch 300/916 | Train Loss: 0.0323 (P: 0.0306 V: 0.0185 A: 0.0319 B: 0.0035)
Epoch 5 | Batch 350/916 | Train Loss: 0.0327 (P: 0.0310 V: 0.0189 A: 0.0326 B: 0.0034)
Epoch 5 | Batch 400/916 | Train Loss: 0.0298 (P: 0.0280 V: 0.0187 A: 0.0323 B: 0.0036)
Epoch 5 | Batch 450/916 | Train Loss: 0.0314 (P: 0.0296 V: 0.0191 A: 0.0329 B: 0.0035)
Epoch 5 | Batch 500/916 | Train Loss: 0.0331 (P: 0.0315 V: 0.0184 A: 0.0316 B: 0.0033)
Epoch 5 | Batch 550/916 | Train Loss: 0.0271 (P: 0.0252 V: 0.0177 A: 0.0306 B: 0.0037)
Epoch 5 | Batch 600/916 | Train Loss: 0.0304 (P: 0.0286 V: 0.0175 A: 0.0304 B: 0.0037)
Epoch 5 | Batch 650/916 | Train Loss: 0.0286 (P: 0.0268 V: 0.0175 A: 0.0301 B: 0.0036)
Epoch 5 | Batch 700/916 | Train Loss: 0.0260 (P: 0.0242 V: 0.0174 A: 0.0300 B: 0.0036)
Epoch 5 | Batch 750/916 | Train Loss: 0.0279 (P: 0.0260 V: 0.0178 A: 0.0306 B: 0.0037)
Epoch 5 | Batch 800/916 | Train Loss: 0.0295 (P: 0.0277 V: 0.0175 A: 0.0301 B: 0.0035)
Epoch 5 | Batch 850/916 | Train Loss: 0.0294 (P: 0.0277 V: 0.0172 A: 0.0297 B: 0.0035)
Epoch 5 | Batch 900/916 | Train Loss: 0.0261 (P: 0.0244 V: 0.0169 A: 0.0291 B: 0.0035)
Epoch 5/10 | Avg Train Loss: 0.0313 (P: 0.0295 V: 0.0183 A: 0.0316 B: 0.0035)
Epoch 5 | Val Loss: 0.0294 MPJPE: 54.94mm (P: 0.0276 V: 0.0014 A: 0.0015 B: 0.0037)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_005_valloss_0.0294_mpjpe_54.94_B_0.0037.pth
Epoch 6 | Batch 0/916 | Train Loss: 0.0283 (P: 0.0265 V: 0.0174 A: 0.0301 B: 0.0036)
Epoch 6 | Batch 50/916 | Train Loss: 0.0265 (P: 0.0247 V: 0.0161 A: 0.0277 B: 0.0036)
Epoch 6 | Batch 100/916 | Train Loss: 0.0287 (P: 0.0269 V: 0.0165 A: 0.0284 B: 0.0036)
Epoch 6 | Batch 150/916 | Train Loss: 0.0294 (P: 0.0276 V: 0.0166 A: 0.0285 B: 0.0035)
Epoch 6 | Batch 200/916 | Train Loss: 0.0287 (P: 0.0269 V: 0.0161 A: 0.0277 B: 0.0037)
Epoch 6 | Batch 250/916 | Train Loss: 0.0308 (P: 0.0289 V: 0.0158 A: 0.0275 B: 0.0037)
Epoch 6 | Batch 300/916 | Train Loss: 0.0272 (P: 0.0253 V: 0.0158 A: 0.0273 B: 0.0037)
Epoch 6 | Batch 350/916 | Train Loss: 0.0267 (P: 0.0248 V: 0.0162 A: 0.0278 B: 0.0036)
Epoch 6 | Batch 400/916 | Train Loss: 0.0301 (P: 0.0284 V: 0.0158 A: 0.0272 B: 0.0034)
Epoch 6 | Batch 450/916 | Train Loss: 0.0290 (P: 0.0272 V: 0.0161 A: 0.0277 B: 0.0036)
Epoch 6 | Batch 500/916 | Train Loss: 0.0304 (P: 0.0286 V: 0.0162 A: 0.0281 B: 0.0036)
Epoch 6 | Batch 550/916 | Train Loss: 0.0302 (P: 0.0284 V: 0.0160 A: 0.0277 B: 0.0035)
Epoch 6 | Batch 600/916 | Train Loss: 0.0271 (P: 0.0253 V: 0.0152 A: 0.0261 B: 0.0037)
Epoch 6 | Batch 650/916 | Train Loss: 0.0282 (P: 0.0263 V: 0.0156 A: 0.0268 B: 0.0038)
Epoch 6 | Batch 700/916 | Train Loss: 0.0255 (P: 0.0236 V: 0.0152 A: 0.0263 B: 0.0036)
Epoch 6 | Batch 750/916 | Train Loss: 0.0258 (P: 0.0240 V: 0.0154 A: 0.0266 B: 0.0038)
Epoch 6 | Batch 800/916 | Train Loss: 0.0274 (P: 0.0256 V: 0.0148 A: 0.0256 B: 0.0036)
Epoch 6 | Batch 850/916 | Train Loss: 0.0250 (P: 0.0231 V: 0.0145 A: 0.0251 B: 0.0038)
Epoch 6 | Batch 900/916 | Train Loss: 0.0317 (P: 0.0298 V: 0.0153 A: 0.0265 B: 0.0038)
Epoch 6/10 | Avg Train Loss: 0.0282 (P: 0.0264 V: 0.0159 A: 0.0273 B: 0.0036)
Epoch 6 | Val Loss: 0.0315 MPJPE: 59.84mm (P: 0.0296 V: 0.0014 A: 0.0014 B: 0.0039)
Epoch 7 | Batch 0/916 | Train Loss: 0.0299 (P: 0.0280 V: 0.0155 A: 0.0269 B: 0.0038)
Epoch 7 | Batch 50/916 | Train Loss: 0.0298 (P: 0.0280 V: 0.0151 A: 0.0261 B: 0.0036)
Epoch 7 | Batch 100/916 | Train Loss: 0.0284 (P: 0.0265 V: 0.0144 A: 0.0247 B: 0.0037)
Epoch 7 | Batch 150/916 | Train Loss: 0.0264 (P: 0.0246 V: 0.0145 A: 0.0250 B: 0.0037)
Epoch 7 | Batch 200/916 | Train Loss: 0.0309 (P: 0.0291 V: 0.0144 A: 0.0249 B: 0.0037)
Epoch 7 | Batch 250/916 | Train Loss: 0.0248 (P: 0.0230 V: 0.0142 A: 0.0245 B: 0.0036)
Epoch 7 | Batch 300/916 | Train Loss: 0.0254 (P: 0.0236 V: 0.0141 A: 0.0243 B: 0.0036)
Epoch 7 | Batch 350/916 | Train Loss: 0.0310 (P: 0.0291 V: 0.0145 A: 0.0250 B: 0.0036)
Epoch 7 | Batch 400/916 | Train Loss: 0.0255 (P: 0.0237 V: 0.0140 A: 0.0240 B: 0.0037)
Epoch 7 | Batch 450/916 | Train Loss: 0.0278 (P: 0.0260 V: 0.0142 A: 0.0246 B: 0.0037)
Epoch 7 | Batch 500/916 | Train Loss: 0.0240 (P: 0.0220 V: 0.0137 A: 0.0237 B: 0.0039)
Epoch 7 | Batch 550/916 | Train Loss: 0.0270 (P: 0.0251 V: 0.0137 A: 0.0236 B: 0.0039)
Epoch 7 | Batch 600/916 | Train Loss: 0.0227 (P: 0.0208 V: 0.0135 A: 0.0234 B: 0.0037)
Epoch 7 | Batch 650/916 | Train Loss: 0.0256 (P: 0.0237 V: 0.0138 A: 0.0238 B: 0.0038)
Epoch 7 | Batch 700/916 | Train Loss: 0.0276 (P: 0.0257 V: 0.0132 A: 0.0228 B: 0.0037)
Epoch 7 | Batch 750/916 | Train Loss: 0.0241 (P: 0.0223 V: 0.0135 A: 0.0234 B: 0.0037)
Epoch 7 | Batch 800/916 | Train Loss: 0.0325 (P: 0.0306 V: 0.0129 A: 0.0222 B: 0.0037)
Epoch 7 | Batch 850/916 | Train Loss: 0.0245 (P: 0.0227 V: 0.0128 A: 0.0219 B: 0.0036)
Epoch 7 | Batch 900/916 | Train Loss: 0.0271 (P: 0.0252 V: 0.0131 A: 0.0225 B: 0.0037)
Epoch 7/10 | Avg Train Loss: 0.0269 (P: 0.0250 V: 0.0140 A: 0.0242 B: 0.0037)
Epoch 7 | Val Loss: 0.0275 MPJPE: 51.48mm (P: 0.0256 V: 0.0013 A: 0.0013 B: 0.0039)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_007_valloss_0.0275_mpjpe_51.48_B_0.0039.pth
Epoch 8 | Batch 0/916 | Train Loss: 0.0251 (P: 0.0232 V: 0.0137 A: 0.0238 B: 0.0038)
Epoch 8 | Batch 50/916 | Train Loss: 0.0243 (P: 0.0224 V: 0.0129 A: 0.0222 B: 0.0038)
Epoch 8 | Batch 100/916 | Train Loss: 0.0248 (P: 0.0230 V: 0.0132 A: 0.0228 B: 0.0037)
Epoch 8 | Batch 150/916 | Train Loss: 0.0240 (P: 0.0221 V: 0.0126 A: 0.0218 B: 0.0037)
Epoch 8 | Batch 200/916 | Train Loss: 0.0227 (P: 0.0207 V: 0.0126 A: 0.0217 B: 0.0039)
Epoch 8 | Batch 250/916 | Train Loss: 0.0262 (P: 0.0243 V: 0.0128 A: 0.0221 B: 0.0037)
Epoch 8 | Batch 300/916 | Train Loss: 0.0233 (P: 0.0214 V: 0.0125 A: 0.0214 B: 0.0038)
Epoch 8 | Batch 350/916 | Train Loss: 0.0223 (P: 0.0204 V: 0.0124 A: 0.0213 B: 0.0038)
Epoch 8 | Batch 400/916 | Train Loss: 0.0226 (P: 0.0207 V: 0.0130 A: 0.0224 B: 0.0038)
Epoch 8 | Batch 450/916 | Train Loss: 0.0228 (P: 0.0209 V: 0.0125 A: 0.0217 B: 0.0038)
Epoch 8 | Batch 500/916 | Train Loss: 0.0233 (P: 0.0214 V: 0.0122 A: 0.0210 B: 0.0038)
Epoch 8 | Batch 550/916 | Train Loss: 0.0257 (P: 0.0238 V: 0.0126 A: 0.0218 B: 0.0037)
Epoch 8 | Batch 600/916 | Train Loss: 0.0247 (P: 0.0229 V: 0.0125 A: 0.0215 B: 0.0037)
Epoch 8 | Batch 650/916 | Train Loss: 0.0233 (P: 0.0214 V: 0.0124 A: 0.0214 B: 0.0038)
Epoch 8 | Batch 700/916 | Train Loss: 0.0215 (P: 0.0196 V: 0.0127 A: 0.0219 B: 0.0038)
Epoch 8 | Batch 750/916 | Train Loss: 0.0244 (P: 0.0225 V: 0.0119 A: 0.0204 B: 0.0037)
Epoch 8 | Batch 800/916 | Train Loss: 0.0219 (P: 0.0200 V: 0.0118 A: 0.0203 B: 0.0039)
Epoch 8 | Batch 850/916 | Train Loss: 0.0225 (P: 0.0205 V: 0.0119 A: 0.0205 B: 0.0039)
Epoch 8 | Batch 900/916 | Train Loss: 0.0269 (P: 0.0250 V: 0.0118 A: 0.0203 B: 0.0038)
Epoch 8/10 | Avg Train Loss: 0.0248 (P: 0.0229 V: 0.0125 A: 0.0215 B: 0.0038)
Epoch 8 | Val Loss: 0.0261 MPJPE: 49.24mm (P: 0.0242 V: 0.0013 A: 0.0012 B: 0.0038)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_008_valloss_0.0261_mpjpe_49.24_B_0.0038.pth
Epoch 9 | Batch 0/916 | Train Loss: 0.0222 (P: 0.0204 V: 0.0116 A: 0.0200 B: 0.0037)
Epoch 9 | Batch 50/916 | Train Loss: 0.0241 (P: 0.0222 V: 0.0117 A: 0.0202 B: 0.0037)
Epoch 9 | Batch 100/916 | Train Loss: 0.0252 (P: 0.0233 V: 0.0112 A: 0.0194 B: 0.0039)
Epoch 9 | Batch 150/916 | Train Loss: 0.0262 (P: 0.0243 V: 0.0116 A: 0.0199 B: 0.0038)
Epoch 9 | Batch 200/916 | Train Loss: 0.0200 (P: 0.0181 V: 0.0114 A: 0.0197 B: 0.0039)
Epoch 9 | Batch 250/916 | Train Loss: 0.0241 (P: 0.0221 V: 0.0117 A: 0.0201 B: 0.0039)
Epoch 9 | Batch 300/916 | Train Loss: 0.0229 (P: 0.0208 V: 0.0112 A: 0.0194 B: 0.0041)
Epoch 9 | Batch 350/916 | Train Loss: 0.0246 (P: 0.0227 V: 0.0116 A: 0.0201 B: 0.0039)
Epoch 9 | Batch 400/916 | Train Loss: 0.0255 (P: 0.0235 V: 0.0109 A: 0.0187 B: 0.0039)
Epoch 9 | Batch 450/916 | Train Loss: 0.0219 (P: 0.0199 V: 0.0109 A: 0.0188 B: 0.0039)
Epoch 9 | Batch 500/916 | Train Loss: 0.0254 (P: 0.0236 V: 0.0115 A: 0.0198 B: 0.0036)
Epoch 9 | Batch 550/916 | Train Loss: 0.0260 (P: 0.0241 V: 0.0121 A: 0.0207 B: 0.0038)
Epoch 9 | Batch 600/916 | Train Loss: 0.0245 (P: 0.0226 V: 0.0108 A: 0.0187 B: 0.0038)
Epoch 9 | Batch 650/916 | Train Loss: 0.0252 (P: 0.0233 V: 0.0120 A: 0.0206 B: 0.0038)
Epoch 9 | Batch 700/916 | Train Loss: 0.0243 (P: 0.0224 V: 0.0107 A: 0.0184 B: 0.0039)
Epoch 9 | Batch 750/916 | Train Loss: 0.0206 (P: 0.0187 V: 0.0106 A: 0.0183 B: 0.0038)
Epoch 9 | Batch 800/916 | Train Loss: 0.0245 (P: 0.0226 V: 0.0109 A: 0.0188 B: 0.0037)
Epoch 9 | Batch 850/916 | Train Loss: 0.0202 (P: 0.0183 V: 0.0106 A: 0.0182 B: 0.0038)
Epoch 9 | Batch 900/916 | Train Loss: 0.0223 (P: 0.0203 V: 0.0114 A: 0.0197 B: 0.0040)
Epoch 9/10 | Avg Train Loss: 0.0236 (P: 0.0217 V: 0.0113 A: 0.0195 B: 0.0038)
Epoch 9 | Val Loss: 0.0263 MPJPE: 49.03mm (P: 0.0242 V: 0.0012 A: 0.0012 B: 0.0041)
Epoch 10 | Batch 0/916 | Train Loss: 0.0215 (P: 0.0195 V: 0.0107 A: 0.0185 B: 0.0041)
Epoch 10 | Batch 50/916 | Train Loss: 0.0197 (P: 0.0177 V: 0.0110 A: 0.0188 B: 0.0040)
Epoch 10 | Batch 100/916 | Train Loss: 0.0205 (P: 0.0185 V: 0.0105 A: 0.0180 B: 0.0040)
Epoch 10 | Batch 150/916 | Train Loss: 0.0223 (P: 0.0204 V: 0.0105 A: 0.0182 B: 0.0039)
Epoch 10 | Batch 200/916 | Train Loss: 0.0233 (P: 0.0213 V: 0.0107 A: 0.0185 B: 0.0039)
Epoch 10 | Batch 250/916 | Train Loss: 0.0213 (P: 0.0193 V: 0.0102 A: 0.0175 B: 0.0039)
Epoch 10 | Batch 300/916 | Train Loss: 0.0223 (P: 0.0204 V: 0.0110 A: 0.0189 B: 0.0039)
Epoch 10 | Batch 350/916 | Train Loss: 0.0239 (P: 0.0219 V: 0.0105 A: 0.0181 B: 0.0039)
Epoch 10 | Batch 400/916 | Train Loss: 0.0193 (P: 0.0173 V: 0.0103 A: 0.0176 B: 0.0040)
Epoch 10 | Batch 450/916 | Train Loss: 0.0192 (P: 0.0172 V: 0.0099 A: 0.0170 B: 0.0040)
Epoch 10 | Batch 500/916 | Train Loss: 0.0221 (P: 0.0201 V: 0.0097 A: 0.0168 B: 0.0039)
Epoch 10 | Batch 550/916 | Train Loss: 0.0224 (P: 0.0205 V: 0.0106 A: 0.0182 B: 0.0039)
Epoch 10 | Batch 600/916 | Train Loss: 0.0198 (P: 0.0178 V: 0.0102 A: 0.0176 B: 0.0040)
Epoch 10 | Batch 650/916 | Train Loss: 0.0198 (P: 0.0179 V: 0.0105 A: 0.0180 B: 0.0040)
Epoch 10 | Batch 700/916 | Train Loss: 0.0212 (P: 0.0192 V: 0.0104 A: 0.0180 B: 0.0040)
Epoch 10 | Batch 750/916 | Train Loss: 0.0214 (P: 0.0194 V: 0.0100 A: 0.0172 B: 0.0040)
Epoch 10 | Batch 800/916 | Train Loss: 0.0195 (P: 0.0174 V: 0.0098 A: 0.0169 B: 0.0041)
Epoch 10 | Batch 850/916 | Train Loss: 0.0227 (P: 0.0207 V: 0.0099 A: 0.0170 B: 0.0040)
Epoch 10 | Batch 900/916 | Train Loss: 0.0217 (P: 0.0197 V: 0.0098 A: 0.0168 B: 0.0039)
Epoch 10/10 | Avg Train Loss: 0.0219 (P: 0.0199 V: 0.0103 A: 0.0177 B: 0.0040)
Epoch 10 | Val Loss: 0.0270 MPJPE: 50.65mm (P: 0.0250 V: 0.0013 A: 0.0012 B: 0.0040)
Training finished for run: training_check_1
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 10, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 1005 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 854 training files, 151 validation files.
Training dataset size: 1243092, Validation dataset size: 223671
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 1005 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 854 training files, 151 validation files.
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 1, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 94 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 79 training files, 15 validation files.
Training dataset size: 83381, Validation dataset size: 15362
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/1303 | Train Loss: 1.0194 (P: 0.9784 V: 0.9372 A: 1.6362 B: 0.4092)
Epoch 1 | Batch 50/1303 | Train Loss: 0.1770 (P: 0.1758 V: 0.1181 A: 0.2048 B: 0.0126)
Epoch 1 | Batch 100/1303 | Train Loss: 0.1369 (P: 0.1364 V: 0.1028 A: 0.1782 B: 0.0050)
Epoch 1 | Batch 150/1303 | Train Loss: 0.1082 (P: 0.1076 V: 0.0899 A: 0.1555 B: 0.0054)
Epoch 1 | Batch 200/1303 | Train Loss: 0.1066 (P: 0.1060 V: 0.0844 A: 0.1458 B: 0.0054)
Epoch 1 | Batch 250/1303 | Train Loss: 0.1154 (P: 0.1148 V: 0.0774 A: 0.1341 B: 0.0056)
Epoch 1 | Batch 300/1303 | Train Loss: 0.0822 (P: 0.0816 V: 0.0726 A: 0.1259 B: 0.0061)
Epoch 1 | Batch 350/1303 | Train Loss: 0.0834 (P: 0.0828 V: 0.0664 A: 0.1151 B: 0.0059)
Epoch 1 | Batch 400/1303 | Train Loss: 0.0716 (P: 0.0710 V: 0.0622 A: 0.1071 B: 0.0060)
Epoch 1 | Batch 450/1303 | Train Loss: 0.0692 (P: 0.0686 V: 0.0587 A: 0.1015 B: 0.0059)
Epoch 1 | Batch 500/1303 | Train Loss: 0.0650 (P: 0.0644 V: 0.0562 A: 0.0969 B: 0.0061)
Epoch 1 | Batch 550/1303 | Train Loss: 0.0618 (P: 0.0612 V: 0.0523 A: 0.0906 B: 0.0061)
Epoch 1 | Batch 600/1303 | Train Loss: 0.0612 (P: 0.0605 V: 0.0514 A: 0.0890 B: 0.0063)
Epoch 1 | Batch 650/1303 | Train Loss: 0.0686 (P: 0.0680 V: 0.0483 A: 0.0834 B: 0.0060)
Epoch 1 | Batch 700/1303 | Train Loss: 0.0566 (P: 0.0561 V: 0.0469 A: 0.0811 B: 0.0057)
Epoch 1 | Batch 750/1303 | Train Loss: 0.0615 (P: 0.0610 V: 0.0452 A: 0.0782 B: 0.0058)
Epoch 1 | Batch 800/1303 | Train Loss: 0.0604 (P: 0.0598 V: 0.0441 A: 0.0762 B: 0.0061)
Epoch 1 | Batch 850/1303 | Train Loss: 0.0554 (P: 0.0548 V: 0.0422 A: 0.0729 B: 0.0063)
Epoch 1 | Batch 900/1303 | Train Loss: 0.0541 (P: 0.0535 V: 0.0400 A: 0.0693 B: 0.0065)
Epoch 1 | Batch 950/1303 | Train Loss: 0.0529 (P: 0.0523 V: 0.0398 A: 0.0685 B: 0.0061)
Epoch 1 | Batch 1000/1303 | Train Loss: 0.0507 (P: 0.0501 V: 0.0397 A: 0.0688 B: 0.0063)
Epoch 1 | Batch 1050/1303 | Train Loss: 0.0533 (P: 0.0527 V: 0.0373 A: 0.0642 B: 0.0063)
Epoch 1 | Batch 1100/1303 | Train Loss: 0.0455 (P: 0.0449 V: 0.0357 A: 0.0619 B: 0.0063)
Epoch 1 | Batch 1150/1303 | Train Loss: 0.0481 (P: 0.0474 V: 0.0351 A: 0.0606 B: 0.0063)
Epoch 1 | Batch 1200/1303 | Train Loss: 0.0519 (P: 0.0513 V: 0.0343 A: 0.0592 B: 0.0063)
Epoch 1 | Batch 1250/1303 | Train Loss: 0.0437 (P: 0.0431 V: 0.0335 A: 0.0580 B: 0.0063)
Epoch 1 | Batch 1300/1303 | Train Loss: 0.0423 (P: 0.0417 V: 0.0324 A: 0.0560 B: 0.0062)
Epoch 1/1 | Avg Train Loss: 0.0800 (P: 0.0792 V: 0.0591 A: 0.1023 B: 0.0079)
Epoch 1 | Val Loss: 0.0402 MPJPE: 80.18mm (P: 0.0396 V: 0.0030 A: 0.0034 B: 0.0064)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_001_valloss_0.0402_mpjpe_80.18_B_0.0064.pth
Training finished for run: training_check_1
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 10, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 1257 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 1068 training files, 189 validation files.
Training dataset size: 2021012, Validation dataset size: 397533
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Starting training run: training_check_1
Arguments: {'model_type': 'transformer', 'amass_root_dir': 'data/CMU', 'val_split_ratio': 0.15, 'split_seed': 42, 'simple_data_paths_train': None, 'simple_data_paths_val': None, 'checkpoint_dir': 'checkpoints/training_check', 'log_dir': 'results/logs/training_check', 'skeleton_type': 'smpl_24', 'window_size': 31, 'center_around_root_amass': True, 'gaussian_noise_std_train': 0.0, 'temporal_noise_type': 'none', 'temporal_noise_scale': 0.0, 'temporal_filter_window': 5, 'temporal_event_prob': 0.05, 'temporal_decay': 0.8, 'outlier_prob': 0.0, 'outlier_scale': 0.0, 'bonelen_noise_scale': 0.0, 'd_model_transformer': 512, 'nhead_transformer': 8, 'num_encoder_layers_transformer': 4, 'num_decoder_layers_transformer': 4, 'dim_feedforward_transformer': 2048, 'dropout_transformer': 0.1, 'use_quaternions_transformer': True, 'd_model_simple': 96, 'nhead_simple': 8, 'num_encoder_layers_simple': 4, 'dim_feedforward_simple': 256, 'dropout_simple': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 10, 'device': 'cuda', 'num_workers': 4, 'w_tf_loss_pose': 1.0, 'w_tf_loss_vel': 0.0, 'w_tf_loss_accel': 0.0, 'w_tf_loss_bone': 0.1, 'w_simple_loss_pose': 1.0, 'w_simple_loss_bone': 0.1, 'run_name': 'training_check_1'}
Using SMPL+H to smpl_24 joint mapping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 20, 21]
Loading AMASS dataset for Transformer model from root: data/CMU
Found 94 .npz files in data/CMU and its subdirectories.
Splitting AMASS data: 79 training files, 15 validation files.
Training dataset size: 83381, Validation dataset size: 15362
Training model: transformer on device: cuda with 24 joints.
Number of parameters: 29,544,063
Epoch 1 | Batch 0/1303 | Train Loss: 0.8258 (P: 0.8000 V: 0.6551 A: 1.1351 B: 0.2584)
Epoch 1 | Batch 50/1303 | Train Loss: 0.1779 (P: 0.1771 V: 0.1177 A: 0.2040 B: 0.0077)
Epoch 1 | Batch 100/1303 | Train Loss: 0.1649 (P: 0.1641 V: 0.0999 A: 0.1719 B: 0.0074)
Epoch 1 | Batch 150/1303 | Train Loss: 0.1300 (P: 0.1293 V: 0.0920 A: 0.1587 B: 0.0073)
Epoch 1 | Batch 200/1303 | Train Loss: 0.1101 (P: 0.1094 V: 0.0859 A: 0.1483 B: 0.0077)
Epoch 1 | Batch 250/1303 | Train Loss: 0.0950 (P: 0.0943 V: 0.0789 A: 0.1366 B: 0.0079)
Epoch 1 | Batch 300/1303 | Train Loss: 0.1231 (P: 0.1223 V: 0.0715 A: 0.1240 B: 0.0076)
Epoch 1 | Batch 350/1303 | Train Loss: 0.0922 (P: 0.0914 V: 0.0695 A: 0.1198 B: 0.0072)
Epoch 1 | Batch 400/1303 | Train Loss: 0.0763 (P: 0.0756 V: 0.0645 A: 0.1124 B: 0.0072)
Epoch 1 | Batch 450/1303 | Train Loss: 0.0776 (P: 0.0769 V: 0.0607 A: 0.1048 B: 0.0074)
Epoch 1 | Batch 500/1303 | Train Loss: 0.0838 (P: 0.0831 V: 0.0555 A: 0.0957 B: 0.0067)
Epoch 1 | Batch 550/1303 | Train Loss: 0.0771 (P: 0.0764 V: 0.0555 A: 0.0965 B: 0.0072)
Epoch 1 | Batch 600/1303 | Train Loss: 0.0724 (P: 0.0717 V: 0.0515 A: 0.0893 B: 0.0072)
Epoch 1 | Batch 650/1303 | Train Loss: 0.0607 (P: 0.0600 V: 0.0484 A: 0.0837 B: 0.0069)
Epoch 1 | Batch 700/1303 | Train Loss: 0.0584 (P: 0.0577 V: 0.0476 A: 0.0822 B: 0.0068)
Epoch 1 | Batch 750/1303 | Train Loss: 0.0611 (P: 0.0604 V: 0.0435 A: 0.0750 B: 0.0069)
Epoch 1 | Batch 800/1303 | Train Loss: 0.0578 (P: 0.0571 V: 0.0438 A: 0.0756 B: 0.0070)
Epoch 1 | Batch 850/1303 | Train Loss: 0.0518 (P: 0.0511 V: 0.0417 A: 0.0719 B: 0.0070)
Epoch 1 | Batch 900/1303 | Train Loss: 0.0590 (P: 0.0583 V: 0.0413 A: 0.0713 B: 0.0070)
Epoch 1 | Batch 950/1303 | Train Loss: 0.0523 (P: 0.0516 V: 0.0398 A: 0.0687 B: 0.0070)
Epoch 1 | Batch 1000/1303 | Train Loss: 0.0489 (P: 0.0482 V: 0.0382 A: 0.0660 B: 0.0071)
Epoch 1 | Batch 1050/1303 | Train Loss: 0.0531 (P: 0.0524 V: 0.0370 A: 0.0634 B: 0.0071)
Epoch 1 | Batch 1100/1303 | Train Loss: 0.0601 (P: 0.0594 V: 0.0373 A: 0.0645 B: 0.0071)
Epoch 1 | Batch 1150/1303 | Train Loss: 0.0502 (P: 0.0495 V: 0.0371 A: 0.0640 B: 0.0069)
Epoch 1 | Batch 1200/1303 | Train Loss: 0.0495 (P: 0.0488 V: 0.0344 A: 0.0595 B: 0.0071)
Epoch 1 | Batch 1250/1303 | Train Loss: 0.0464 (P: 0.0457 V: 0.0335 A: 0.0579 B: 0.0071)
Epoch 1 | Batch 1300/1303 | Train Loss: 0.0523 (P: 0.0515 V: 0.0326 A: 0.0561 B: 0.0073)
Epoch 1/10 | Avg Train Loss: 0.0869 (P: 0.0860 V: 0.0592 A: 0.1025 B: 0.0085)
Epoch 1 | Val Loss: 0.0473 MPJPE: 93.89mm (P: 0.0466 V: 0.0031 A: 0.0034 B: 0.0072)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_001_valloss_0.0473_mpjpe_93.89_B_0.0072.pth
Epoch 2 | Batch 0/1303 | Train Loss: 0.0502 (P: 0.0495 V: 0.0319 A: 0.0552 B: 0.0073)
Epoch 2 | Batch 50/1303 | Train Loss: 0.0482 (P: 0.0475 V: 0.0319 A: 0.0551 B: 0.0072)
Epoch 2 | Batch 100/1303 | Train Loss: 0.0493 (P: 0.0486 V: 0.0327 A: 0.0564 B: 0.0071)
Epoch 2 | Batch 150/1303 | Train Loss: 0.0467 (P: 0.0460 V: 0.0308 A: 0.0532 B: 0.0071)
Epoch 2 | Batch 200/1303 | Train Loss: 0.0417 (P: 0.0410 V: 0.0296 A: 0.0509 B: 0.0070)
Epoch 2 | Batch 250/1303 | Train Loss: 0.0451 (P: 0.0443 V: 0.0289 A: 0.0499 B: 0.0072)
Epoch 2 | Batch 300/1303 | Train Loss: 0.0418 (P: 0.0411 V: 0.0286 A: 0.0491 B: 0.0071)
Epoch 2 | Batch 350/1303 | Train Loss: 0.0417 (P: 0.0410 V: 0.0284 A: 0.0490 B: 0.0072)
Epoch 2 | Batch 400/1303 | Train Loss: 0.0441 (P: 0.0434 V: 0.0295 A: 0.0509 B: 0.0070)
Epoch 2 | Batch 450/1303 | Train Loss: 0.0438 (P: 0.0431 V: 0.0283 A: 0.0489 B: 0.0069)
Epoch 2 | Batch 500/1303 | Train Loss: 0.0415 (P: 0.0408 V: 0.0271 A: 0.0467 B: 0.0072)
Epoch 2 | Batch 550/1303 | Train Loss: 0.0414 (P: 0.0407 V: 0.0273 A: 0.0472 B: 0.0071)
Epoch 2 | Batch 600/1303 | Train Loss: 0.0412 (P: 0.0405 V: 0.0277 A: 0.0477 B: 0.0070)
Epoch 2 | Batch 650/1303 | Train Loss: 0.0406 (P: 0.0398 V: 0.0265 A: 0.0457 B: 0.0072)
Epoch 2 | Batch 700/1303 | Train Loss: 0.0389 (P: 0.0382 V: 0.0257 A: 0.0443 B: 0.0073)
Epoch 2 | Batch 750/1303 | Train Loss: 0.0419 (P: 0.0411 V: 0.0262 A: 0.0453 B: 0.0074)
Epoch 2 | Batch 800/1303 | Train Loss: 0.0360 (P: 0.0352 V: 0.0266 A: 0.0458 B: 0.0072)
Epoch 2 | Batch 850/1303 | Train Loss: 0.0353 (P: 0.0346 V: 0.0255 A: 0.0440 B: 0.0071)
Epoch 2 | Batch 900/1303 | Train Loss: 0.0340 (P: 0.0332 V: 0.0238 A: 0.0411 B: 0.0074)
Epoch 2 | Batch 950/1303 | Train Loss: 0.0355 (P: 0.0347 V: 0.0247 A: 0.0426 B: 0.0072)
Epoch 2 | Batch 1000/1303 | Train Loss: 0.0350 (P: 0.0343 V: 0.0248 A: 0.0428 B: 0.0072)
Epoch 2 | Batch 1050/1303 | Train Loss: 0.0330 (P: 0.0322 V: 0.0237 A: 0.0409 B: 0.0073)
Epoch 2 | Batch 1100/1303 | Train Loss: 0.0347 (P: 0.0340 V: 0.0244 A: 0.0423 B: 0.0074)
Epoch 2 | Batch 1150/1303 | Train Loss: 0.0352 (P: 0.0345 V: 0.0230 A: 0.0397 B: 0.0072)
Epoch 2 | Batch 1200/1303 | Train Loss: 0.0327 (P: 0.0320 V: 0.0230 A: 0.0397 B: 0.0073)
Epoch 2 | Batch 1250/1303 | Train Loss: 0.0326 (P: 0.0319 V: 0.0223 A: 0.0386 B: 0.0073)
Epoch 2 | Batch 1300/1303 | Train Loss: 0.0327 (P: 0.0320 V: 0.0225 A: 0.0390 B: 0.0072)
Epoch 2/10 | Avg Train Loss: 0.0405 (P: 0.0397 V: 0.0269 A: 0.0464 B: 0.0072)
Epoch 2 | Val Loss: 0.0309 MPJPE: 61.48mm (P: 0.0302 V: 0.0020 A: 0.0023 B: 0.0073)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_002_valloss_0.0309_mpjpe_61.48_B_0.0073.pth
Epoch 3 | Batch 0/1303 | Train Loss: 0.0328 (P: 0.0320 V: 0.0223 A: 0.0386 B: 0.0073)
Epoch 3 | Batch 50/1303 | Train Loss: 0.0332 (P: 0.0324 V: 0.0229 A: 0.0394 B: 0.0074)
Epoch 3 | Batch 100/1303 | Train Loss: 0.0306 (P: 0.0299 V: 0.0222 A: 0.0383 B: 0.0074)
Epoch 3 | Batch 150/1303 | Train Loss: 0.0313 (P: 0.0306 V: 0.0213 A: 0.0367 B: 0.0072)
Epoch 3 | Batch 200/1303 | Train Loss: 0.0301 (P: 0.0293 V: 0.0212 A: 0.0366 B: 0.0072)
Epoch 3 | Batch 250/1303 | Train Loss: 0.0295 (P: 0.0287 V: 0.0205 A: 0.0352 B: 0.0073)
Epoch 3 | Batch 300/1303 | Train Loss: 0.0329 (P: 0.0321 V: 0.0207 A: 0.0355 B: 0.0074)
Epoch 3 | Batch 350/1303 | Train Loss: 0.0341 (P: 0.0333 V: 0.0207 A: 0.0356 B: 0.0074)
Epoch 3 | Batch 400/1303 | Train Loss: 0.0353 (P: 0.0346 V: 0.0209 A: 0.0361 B: 0.0074)
Epoch 3 | Batch 450/1303 | Train Loss: 0.0315 (P: 0.0308 V: 0.0206 A: 0.0355 B: 0.0073)
Epoch 3 | Batch 500/1303 | Train Loss: 0.0306 (P: 0.0298 V: 0.0200 A: 0.0344 B: 0.0073)
Epoch 3 | Batch 550/1303 | Train Loss: 0.0282 (P: 0.0275 V: 0.0192 A: 0.0331 B: 0.0076)
Epoch 3 | Batch 600/1303 | Train Loss: 0.0327 (P: 0.0320 V: 0.0197 A: 0.0342 B: 0.0073)
Epoch 3 | Batch 650/1303 | Train Loss: 0.0290 (P: 0.0283 V: 0.0191 A: 0.0328 B: 0.0074)
Epoch 3 | Batch 700/1303 | Train Loss: 0.0309 (P: 0.0302 V: 0.0201 A: 0.0347 B: 0.0073)
Epoch 3 | Batch 750/1303 | Train Loss: 0.0292 (P: 0.0285 V: 0.0186 A: 0.0321 B: 0.0076)
Epoch 3 | Batch 800/1303 | Train Loss: 0.0279 (P: 0.0271 V: 0.0186 A: 0.0320 B: 0.0075)
Epoch 3 | Batch 850/1303 | Train Loss: 0.0292 (P: 0.0285 V: 0.0191 A: 0.0329 B: 0.0072)
Epoch 3 | Batch 900/1303 | Train Loss: 0.0295 (P: 0.0288 V: 0.0188 A: 0.0324 B: 0.0072)
Epoch 3 | Batch 950/1303 | Train Loss: 0.0333 (P: 0.0326 V: 0.0191 A: 0.0329 B: 0.0073)
Epoch 3 | Batch 1000/1303 | Train Loss: 0.0274 (P: 0.0267 V: 0.0179 A: 0.0308 B: 0.0072)
Epoch 3 | Batch 1050/1303 | Train Loss: 0.0289 (P: 0.0281 V: 0.0183 A: 0.0313 B: 0.0073)
Epoch 3 | Batch 1100/1303 | Train Loss: 0.0290 (P: 0.0283 V: 0.0175 A: 0.0300 B: 0.0074)
Epoch 3 | Batch 1150/1303 | Train Loss: 0.0327 (P: 0.0319 V: 0.0179 A: 0.0310 B: 0.0073)
Epoch 3 | Batch 1200/1303 | Train Loss: 0.0268 (P: 0.0261 V: 0.0174 A: 0.0300 B: 0.0072)
Epoch 3 | Batch 1250/1303 | Train Loss: 0.0297 (P: 0.0290 V: 0.0175 A: 0.0303 B: 0.0073)
Epoch 3 | Batch 1300/1303 | Train Loss: 0.0258 (P: 0.0250 V: 0.0171 A: 0.0295 B: 0.0076)
Epoch 3/10 | Avg Train Loss: 0.0309 (P: 0.0301 V: 0.0195 A: 0.0337 B: 0.0073)
Epoch 3 | Val Loss: 0.0253 MPJPE: 50.70mm (P: 0.0246 V: 0.0016 A: 0.0018 B: 0.0073)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_003_valloss_0.0253_mpjpe_50.70_B_0.0073.pth
Epoch 4 | Batch 0/1303 | Train Loss: 0.0258 (P: 0.0250 V: 0.0166 A: 0.0286 B: 0.0074)
Epoch 4 | Batch 50/1303 | Train Loss: 0.0274 (P: 0.0266 V: 0.0172 A: 0.0295 B: 0.0075)
Epoch 4 | Batch 100/1303 | Train Loss: 0.0267 (P: 0.0259 V: 0.0163 A: 0.0279 B: 0.0074)
Epoch 4 | Batch 150/1303 | Train Loss: 0.0289 (P: 0.0282 V: 0.0168 A: 0.0290 B: 0.0075)
Epoch 4 | Batch 200/1303 | Train Loss: 0.0253 (P: 0.0245 V: 0.0163 A: 0.0281 B: 0.0075)
Epoch 4 | Batch 250/1303 | Train Loss: 0.0247 (P: 0.0240 V: 0.0160 A: 0.0275 B: 0.0073)
Epoch 4 | Batch 300/1303 | Train Loss: 0.0258 (P: 0.0251 V: 0.0160 A: 0.0277 B: 0.0075)
Epoch 4 | Batch 350/1303 | Train Loss: 0.0265 (P: 0.0258 V: 0.0157 A: 0.0271 B: 0.0073)
Epoch 4 | Batch 400/1303 | Train Loss: 0.0323 (P: 0.0316 V: 0.0158 A: 0.0271 B: 0.0075)
Epoch 4 | Batch 450/1303 | Train Loss: 0.0296 (P: 0.0289 V: 0.0165 A: 0.0284 B: 0.0073)
Epoch 4 | Batch 500/1303 | Train Loss: 0.0262 (P: 0.0255 V: 0.0160 A: 0.0275 B: 0.0074)
Epoch 4 | Batch 550/1303 | Train Loss: 0.0293 (P: 0.0286 V: 0.0149 A: 0.0257 B: 0.0075)
Epoch 4 | Batch 600/1303 | Train Loss: 0.0246 (P: 0.0238 V: 0.0154 A: 0.0266 B: 0.0075)
Epoch 4 | Batch 650/1303 | Train Loss: 0.0249 (P: 0.0242 V: 0.0150 A: 0.0258 B: 0.0075)
Epoch 4 | Batch 700/1303 | Train Loss: 0.0254 (P: 0.0247 V: 0.0150 A: 0.0260 B: 0.0074)
Epoch 4 | Batch 750/1303 | Train Loss: 0.0270 (P: 0.0262 V: 0.0149 A: 0.0258 B: 0.0074)
Epoch 4 | Batch 800/1303 | Train Loss: 0.0248 (P: 0.0241 V: 0.0142 A: 0.0246 B: 0.0075)
Epoch 4 | Batch 850/1303 | Train Loss: 0.0251 (P: 0.0244 V: 0.0146 A: 0.0252 B: 0.0074)
Epoch 4 | Batch 900/1303 | Train Loss: 0.0261 (P: 0.0254 V: 0.0146 A: 0.0251 B: 0.0074)
Epoch 4 | Batch 950/1303 | Train Loss: 0.0264 (P: 0.0257 V: 0.0148 A: 0.0255 B: 0.0073)
Epoch 4 | Batch 1000/1303 | Train Loss: 0.0287 (P: 0.0280 V: 0.0143 A: 0.0246 B: 0.0073)
Epoch 4 | Batch 1050/1303 | Train Loss: 0.0259 (P: 0.0252 V: 0.0145 A: 0.0251 B: 0.0074)
Epoch 4 | Batch 1100/1303 | Train Loss: 0.0268 (P: 0.0260 V: 0.0150 A: 0.0259 B: 0.0076)
Epoch 4 | Batch 1150/1303 | Train Loss: 0.0270 (P: 0.0263 V: 0.0137 A: 0.0236 B: 0.0075)
Epoch 4 | Batch 1200/1303 | Train Loss: 0.0247 (P: 0.0239 V: 0.0142 A: 0.0245 B: 0.0074)
Epoch 4 | Batch 1250/1303 | Train Loss: 0.0263 (P: 0.0256 V: 0.0135 A: 0.0233 B: 0.0074)
Epoch 4 | Batch 1300/1303 | Train Loss: 0.0256 (P: 0.0249 V: 0.0135 A: 0.0232 B: 0.0075)
Epoch 4/10 | Avg Train Loss: 0.0268 (P: 0.0261 V: 0.0153 A: 0.0264 B: 0.0074)
Epoch 4 | Val Loss: 0.0247 MPJPE: 49.40mm (P: 0.0239 V: 0.0014 A: 0.0015 B: 0.0073)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_004_valloss_0.0247_mpjpe_49.40_B_0.0073.pth
Epoch 5 | Batch 0/1303 | Train Loss: 0.0245 (P: 0.0237 V: 0.0132 A: 0.0229 B: 0.0076)
Epoch 5 | Batch 50/1303 | Train Loss: 0.0248 (P: 0.0241 V: 0.0133 A: 0.0228 B: 0.0074)
Epoch 5 | Batch 100/1303 | Train Loss: 0.0246 (P: 0.0238 V: 0.0130 A: 0.0224 B: 0.0075)
Epoch 5 | Batch 150/1303 | Train Loss: 0.0256 (P: 0.0249 V: 0.0137 A: 0.0236 B: 0.0074)
Epoch 5 | Batch 200/1303 | Train Loss: 0.0228 (P: 0.0220 V: 0.0125 A: 0.0216 B: 0.0075)
Epoch 5 | Batch 250/1303 | Train Loss: 0.0226 (P: 0.0219 V: 0.0130 A: 0.0224 B: 0.0075)
Epoch 5 | Batch 300/1303 | Train Loss: 0.0227 (P: 0.0220 V: 0.0129 A: 0.0222 B: 0.0075)
Epoch 5 | Batch 350/1303 | Train Loss: 0.0239 (P: 0.0232 V: 0.0126 A: 0.0218 B: 0.0075)
Epoch 5 | Batch 400/1303 | Train Loss: 0.0241 (P: 0.0234 V: 0.0129 A: 0.0222 B: 0.0074)
Epoch 5 | Batch 450/1303 | Train Loss: 0.0225 (P: 0.0218 V: 0.0123 A: 0.0212 B: 0.0075)
Epoch 5 | Batch 500/1303 | Train Loss: 0.0236 (P: 0.0229 V: 0.0127 A: 0.0220 B: 0.0072)
Epoch 5 | Batch 550/1303 | Train Loss: 0.0230 (P: 0.0222 V: 0.0124 A: 0.0212 B: 0.0075)
Epoch 5 | Batch 600/1303 | Train Loss: 0.0226 (P: 0.0219 V: 0.0122 A: 0.0209 B: 0.0075)
Epoch 5 | Batch 650/1303 | Train Loss: 0.0229 (P: 0.0221 V: 0.0125 A: 0.0216 B: 0.0076)
Epoch 5 | Batch 700/1303 | Train Loss: 0.0221 (P: 0.0214 V: 0.0117 A: 0.0200 B: 0.0074)
Epoch 5 | Batch 750/1303 | Train Loss: 0.0240 (P: 0.0233 V: 0.0121 A: 0.0210 B: 0.0074)
Epoch 5 | Batch 800/1303 | Train Loss: 0.0236 (P: 0.0228 V: 0.0119 A: 0.0205 B: 0.0075)
Epoch 5 | Batch 850/1303 | Train Loss: 0.0251 (P: 0.0243 V: 0.0117 A: 0.0201 B: 0.0073)
Epoch 5 | Batch 900/1303 | Train Loss: 0.0251 (P: 0.0243 V: 0.0122 A: 0.0209 B: 0.0073)
Epoch 5 | Batch 950/1303 | Train Loss: 0.0247 (P: 0.0239 V: 0.0119 A: 0.0204 B: 0.0074)
Epoch 5 | Batch 1000/1303 | Train Loss: 0.0227 (P: 0.0219 V: 0.0121 A: 0.0209 B: 0.0074)
Epoch 5 | Batch 1050/1303 | Train Loss: 0.0232 (P: 0.0224 V: 0.0115 A: 0.0198 B: 0.0075)
Epoch 5 | Batch 1100/1303 | Train Loss: 0.0224 (P: 0.0216 V: 0.0122 A: 0.0208 B: 0.0075)
Epoch 5 | Batch 1150/1303 | Train Loss: 0.0233 (P: 0.0225 V: 0.0118 A: 0.0204 B: 0.0073)
Epoch 5 | Batch 1200/1303 | Train Loss: 0.0232 (P: 0.0225 V: 0.0112 A: 0.0192 B: 0.0075)
Epoch 5 | Batch 1250/1303 | Train Loss: 0.0235 (P: 0.0228 V: 0.0124 A: 0.0213 B: 0.0073)
Epoch 5 | Batch 1300/1303 | Train Loss: 0.0219 (P: 0.0211 V: 0.0110 A: 0.0190 B: 0.0075)
Epoch 5/10 | Avg Train Loss: 0.0237 (P: 0.0230 V: 0.0124 A: 0.0214 B: 0.0074)
Epoch 5 | Val Loss: 0.0234 MPJPE: 46.91mm (P: 0.0227 V: 0.0013 A: 0.0013 B: 0.0073)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_005_valloss_0.0234_mpjpe_46.91_B_0.0073.pth
Epoch 6 | Batch 0/1303 | Train Loss: 0.0224 (P: 0.0217 V: 0.0112 A: 0.0192 B: 0.0075)
Epoch 6 | Batch 50/1303 | Train Loss: 0.0236 (P: 0.0228 V: 0.0108 A: 0.0185 B: 0.0074)
Epoch 6 | Batch 100/1303 | Train Loss: 0.0243 (P: 0.0236 V: 0.0116 A: 0.0200 B: 0.0074)
Epoch 6 | Batch 150/1303 | Train Loss: 0.0250 (P: 0.0243 V: 0.0115 A: 0.0197 B: 0.0074)
Epoch 6 | Batch 200/1303 | Train Loss: 0.0246 (P: 0.0238 V: 0.0107 A: 0.0185 B: 0.0073)
Epoch 6 | Batch 250/1303 | Train Loss: 0.0228 (P: 0.0221 V: 0.0112 A: 0.0193 B: 0.0074)
Epoch 6 | Batch 300/1303 | Train Loss: 0.0215 (P: 0.0207 V: 0.0107 A: 0.0184 B: 0.0074)
Epoch 6 | Batch 350/1303 | Train Loss: 0.0212 (P: 0.0204 V: 0.0106 A: 0.0182 B: 0.0074)
Epoch 6 | Batch 400/1303 | Train Loss: 0.0213 (P: 0.0205 V: 0.0110 A: 0.0190 B: 0.0074)
Epoch 6 | Batch 450/1303 | Train Loss: 0.0220 (P: 0.0212 V: 0.0105 A: 0.0182 B: 0.0073)
Epoch 6 | Batch 500/1303 | Train Loss: 0.0211 (P: 0.0204 V: 0.0105 A: 0.0180 B: 0.0073)
Epoch 6 | Batch 550/1303 | Train Loss: 0.0231 (P: 0.0223 V: 0.0106 A: 0.0181 B: 0.0075)
Epoch 6 | Batch 600/1303 | Train Loss: 0.0218 (P: 0.0211 V: 0.0105 A: 0.0180 B: 0.0074)
Epoch 6 | Batch 650/1303 | Train Loss: 0.0226 (P: 0.0219 V: 0.0105 A: 0.0182 B: 0.0075)
Epoch 6 | Batch 700/1303 | Train Loss: 0.0213 (P: 0.0206 V: 0.0106 A: 0.0182 B: 0.0074)
Epoch 6 | Batch 750/1303 | Train Loss: 0.0214 (P: 0.0207 V: 0.0103 A: 0.0177 B: 0.0074)
Epoch 6 | Batch 800/1303 | Train Loss: 0.0212 (P: 0.0204 V: 0.0102 A: 0.0176 B: 0.0075)
Epoch 6 | Batch 850/1303 | Train Loss: 0.0208 (P: 0.0201 V: 0.0101 A: 0.0173 B: 0.0074)
Epoch 6 | Batch 900/1303 | Train Loss: 0.0199 (P: 0.0192 V: 0.0099 A: 0.0170 B: 0.0073)
Epoch 6 | Batch 950/1303 | Train Loss: 0.0234 (P: 0.0226 V: 0.0104 A: 0.0178 B: 0.0074)
Epoch 6 | Batch 1000/1303 | Train Loss: 0.0208 (P: 0.0201 V: 0.0102 A: 0.0176 B: 0.0074)
Epoch 6 | Batch 1050/1303 | Train Loss: 0.0210 (P: 0.0202 V: 0.0102 A: 0.0175 B: 0.0074)
Epoch 6 | Batch 1100/1303 | Train Loss: 0.0210 (P: 0.0202 V: 0.0100 A: 0.0172 B: 0.0074)
Epoch 6 | Batch 1150/1303 | Train Loss: 0.0204 (P: 0.0197 V: 0.0099 A: 0.0169 B: 0.0074)
Epoch 6 | Batch 1200/1303 | Train Loss: 0.0213 (P: 0.0206 V: 0.0096 A: 0.0165 B: 0.0075)
Epoch 6 | Batch 1250/1303 | Train Loss: 0.0220 (P: 0.0213 V: 0.0096 A: 0.0164 B: 0.0075)
Epoch 6 | Batch 1300/1303 | Train Loss: 0.0213 (P: 0.0206 V: 0.0099 A: 0.0170 B: 0.0075)
Epoch 6/10 | Avg Train Loss: 0.0220 (P: 0.0213 V: 0.0105 A: 0.0180 B: 0.0074)
Epoch 6 | Val Loss: 0.0239 MPJPE: 47.79mm (P: 0.0232 V: 0.0013 A: 0.0013 B: 0.0074)
Epoch 7 | Batch 0/1303 | Train Loss: 0.0221 (P: 0.0213 V: 0.0099 A: 0.0169 B: 0.0075)
Epoch 7 | Batch 50/1303 | Train Loss: 0.0248 (P: 0.0241 V: 0.0099 A: 0.0170 B: 0.0074)
Epoch 7 | Batch 100/1303 | Train Loss: 0.0216 (P: 0.0208 V: 0.0100 A: 0.0171 B: 0.0075)
Epoch 7 | Batch 150/1303 | Train Loss: 0.0206 (P: 0.0198 V: 0.0095 A: 0.0163 B: 0.0076)
Epoch 7 | Batch 200/1303 | Train Loss: 0.0212 (P: 0.0204 V: 0.0098 A: 0.0169 B: 0.0073)
Epoch 7 | Batch 250/1303 | Train Loss: 0.0201 (P: 0.0194 V: 0.0096 A: 0.0164 B: 0.0073)
Epoch 7 | Batch 300/1303 | Train Loss: 0.0208 (P: 0.0201 V: 0.0101 A: 0.0174 B: 0.0073)
Epoch 7 | Batch 350/1303 | Train Loss: 0.0204 (P: 0.0196 V: 0.0096 A: 0.0165 B: 0.0074)
Epoch 7 | Batch 400/1303 | Train Loss: 0.0208 (P: 0.0201 V: 0.0102 A: 0.0176 B: 0.0075)
Epoch 7 | Batch 450/1303 | Train Loss: 0.0199 (P: 0.0192 V: 0.0090 A: 0.0154 B: 0.0075)
Epoch 7 | Batch 500/1303 | Train Loss: 0.0210 (P: 0.0202 V: 0.0096 A: 0.0164 B: 0.0073)
Epoch 7 | Batch 550/1303 | Train Loss: 0.0193 (P: 0.0185 V: 0.0091 A: 0.0156 B: 0.0073)
Epoch 7 | Batch 600/1303 | Train Loss: 0.0218 (P: 0.0211 V: 0.0094 A: 0.0161 B: 0.0073)
Epoch 7 | Batch 650/1303 | Train Loss: 0.0201 (P: 0.0194 V: 0.0090 A: 0.0154 B: 0.0074)
Epoch 7 | Batch 700/1303 | Train Loss: 0.0195 (P: 0.0188 V: 0.0086 A: 0.0148 B: 0.0075)
Epoch 7 | Batch 750/1303 | Train Loss: 0.0195 (P: 0.0187 V: 0.0092 A: 0.0158 B: 0.0073)
Epoch 7 | Batch 800/1303 | Train Loss: 0.0194 (P: 0.0186 V: 0.0085 A: 0.0145 B: 0.0076)
Epoch 7 | Batch 850/1303 | Train Loss: 0.0201 (P: 0.0194 V: 0.0090 A: 0.0154 B: 0.0075)
Epoch 7 | Batch 900/1303 | Train Loss: 0.0190 (P: 0.0183 V: 0.0085 A: 0.0146 B: 0.0074)
Epoch 7 | Batch 950/1303 | Train Loss: 0.0218 (P: 0.0210 V: 0.0085 A: 0.0146 B: 0.0074)
Epoch 7 | Batch 1000/1303 | Train Loss: 0.0196 (P: 0.0188 V: 0.0086 A: 0.0148 B: 0.0074)
Epoch 7 | Batch 1050/1303 | Train Loss: 0.0203 (P: 0.0196 V: 0.0090 A: 0.0154 B: 0.0073)
Epoch 7 | Batch 1100/1303 | Train Loss: 0.0213 (P: 0.0206 V: 0.0085 A: 0.0146 B: 0.0073)
Epoch 7 | Batch 1150/1303 | Train Loss: 0.0205 (P: 0.0198 V: 0.0091 A: 0.0157 B: 0.0074)
Epoch 7 | Batch 1200/1303 | Train Loss: 0.0213 (P: 0.0206 V: 0.0090 A: 0.0155 B: 0.0074)
Epoch 7 | Batch 1250/1303 | Train Loss: 0.0201 (P: 0.0194 V: 0.0086 A: 0.0148 B: 0.0075)
Epoch 7 | Batch 1300/1303 | Train Loss: 0.0203 (P: 0.0195 V: 0.0086 A: 0.0147 B: 0.0074)
Epoch 7/10 | Avg Train Loss: 0.0206 (P: 0.0198 V: 0.0092 A: 0.0157 B: 0.0074)
Epoch 7 | Val Loss: 0.0233 MPJPE: 47.11mm (P: 0.0226 V: 0.0012 A: 0.0012 B: 0.0073)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_007_valloss_0.0233_mpjpe_47.11_B_0.0073.pth
Epoch 8 | Batch 0/1303 | Train Loss: 0.0212 (P: 0.0205 V: 0.0089 A: 0.0152 B: 0.0073)
Epoch 8 | Batch 50/1303 | Train Loss: 0.0202 (P: 0.0195 V: 0.0088 A: 0.0151 B: 0.0074)
Epoch 8 | Batch 100/1303 | Train Loss: 0.0191 (P: 0.0184 V: 0.0084 A: 0.0143 B: 0.0073)
Epoch 8 | Batch 150/1303 | Train Loss: 0.0207 (P: 0.0200 V: 0.0081 A: 0.0139 B: 0.0075)
Epoch 8 | Batch 200/1303 | Train Loss: 0.0216 (P: 0.0208 V: 0.0087 A: 0.0149 B: 0.0072)
Epoch 8 | Batch 250/1303 | Train Loss: 0.0211 (P: 0.0204 V: 0.0083 A: 0.0143 B: 0.0074)
Epoch 8 | Batch 300/1303 | Train Loss: 0.0209 (P: 0.0201 V: 0.0083 A: 0.0142 B: 0.0072)
Epoch 8 | Batch 350/1303 | Train Loss: 0.0188 (P: 0.0180 V: 0.0081 A: 0.0138 B: 0.0074)
Epoch 8 | Batch 400/1303 | Train Loss: 0.0194 (P: 0.0187 V: 0.0089 A: 0.0153 B: 0.0075)
Epoch 8 | Batch 450/1303 | Train Loss: 0.0204 (P: 0.0196 V: 0.0084 A: 0.0145 B: 0.0075)
Epoch 8 | Batch 500/1303 | Train Loss: 0.0181 (P: 0.0174 V: 0.0078 A: 0.0134 B: 0.0075)
Epoch 8 | Batch 550/1303 | Train Loss: 0.0194 (P: 0.0186 V: 0.0084 A: 0.0145 B: 0.0074)
Epoch 8 | Batch 600/1303 | Train Loss: 0.0211 (P: 0.0204 V: 0.0087 A: 0.0149 B: 0.0075)
Epoch 8 | Batch 650/1303 | Train Loss: 0.0185 (P: 0.0177 V: 0.0082 A: 0.0141 B: 0.0075)
Epoch 8 | Batch 700/1303 | Train Loss: 0.0185 (P: 0.0177 V: 0.0081 A: 0.0138 B: 0.0074)
Epoch 8 | Batch 750/1303 | Train Loss: 0.0187 (P: 0.0179 V: 0.0078 A: 0.0134 B: 0.0074)
Epoch 8 | Batch 800/1303 | Train Loss: 0.0200 (P: 0.0192 V: 0.0078 A: 0.0133 B: 0.0075)
Epoch 8 | Batch 850/1303 | Train Loss: 0.0196 (P: 0.0189 V: 0.0079 A: 0.0136 B: 0.0074)
Epoch 8 | Batch 900/1303 | Train Loss: 0.0185 (P: 0.0178 V: 0.0078 A: 0.0134 B: 0.0075)
Epoch 8 | Batch 950/1303 | Train Loss: 0.0189 (P: 0.0181 V: 0.0080 A: 0.0137 B: 0.0074)
Epoch 8 | Batch 1000/1303 | Train Loss: 0.0185 (P: 0.0178 V: 0.0079 A: 0.0135 B: 0.0074)
Epoch 8 | Batch 1050/1303 | Train Loss: 0.0201 (P: 0.0194 V: 0.0079 A: 0.0136 B: 0.0074)
Epoch 8 | Batch 1100/1303 | Train Loss: 0.0183 (P: 0.0175 V: 0.0081 A: 0.0138 B: 0.0075)
Epoch 8 | Batch 1150/1303 | Train Loss: 0.0195 (P: 0.0187 V: 0.0082 A: 0.0141 B: 0.0073)
Epoch 8 | Batch 1200/1303 | Train Loss: 0.0192 (P: 0.0184 V: 0.0078 A: 0.0133 B: 0.0074)
Epoch 8 | Batch 1250/1303 | Train Loss: 0.0180 (P: 0.0172 V: 0.0077 A: 0.0131 B: 0.0073)
Epoch 8 | Batch 1300/1303 | Train Loss: 0.0221 (P: 0.0214 V: 0.0083 A: 0.0143 B: 0.0071)
Epoch 8/10 | Avg Train Loss: 0.0196 (P: 0.0189 V: 0.0083 A: 0.0142 B: 0.0074)
Epoch 8 | Val Loss: 0.0236 MPJPE: 47.36mm (P: 0.0228 V: 0.0012 A: 0.0011 B: 0.0073)
Epoch 9 | Batch 0/1303 | Train Loss: 0.0213 (P: 0.0206 V: 0.0081 A: 0.0139 B: 0.0073)
Epoch 9 | Batch 50/1303 | Train Loss: 0.0186 (P: 0.0179 V: 0.0077 A: 0.0132 B: 0.0075)
Epoch 9 | Batch 100/1303 | Train Loss: 0.0180 (P: 0.0173 V: 0.0082 A: 0.0140 B: 0.0073)
Epoch 9 | Batch 150/1303 | Train Loss: 0.0177 (P: 0.0170 V: 0.0077 A: 0.0132 B: 0.0074)
Epoch 9 | Batch 200/1303 | Train Loss: 0.0183 (P: 0.0176 V: 0.0079 A: 0.0137 B: 0.0075)
Epoch 9 | Batch 250/1303 | Train Loss: 0.0187 (P: 0.0179 V: 0.0077 A: 0.0132 B: 0.0074)
Epoch 9 | Batch 300/1303 | Train Loss: 0.0191 (P: 0.0183 V: 0.0079 A: 0.0135 B: 0.0075)
Epoch 9 | Batch 350/1303 | Train Loss: 0.0187 (P: 0.0180 V: 0.0078 A: 0.0133 B: 0.0073)
Epoch 9 | Batch 400/1303 | Train Loss: 0.0177 (P: 0.0170 V: 0.0076 A: 0.0130 B: 0.0075)
Epoch 9 | Batch 450/1303 | Train Loss: 0.0199 (P: 0.0191 V: 0.0075 A: 0.0128 B: 0.0074)
Epoch 9 | Batch 500/1303 | Train Loss: 0.0187 (P: 0.0180 V: 0.0077 A: 0.0133 B: 0.0074)
Epoch 9 | Batch 550/1303 | Train Loss: 0.0190 (P: 0.0183 V: 0.0076 A: 0.0130 B: 0.0074)
Epoch 9 | Batch 600/1303 | Train Loss: 0.0181 (P: 0.0174 V: 0.0078 A: 0.0132 B: 0.0073)
Epoch 9 | Batch 650/1303 | Train Loss: 0.0192 (P: 0.0185 V: 0.0080 A: 0.0138 B: 0.0074)
Epoch 9 | Batch 700/1303 | Train Loss: 0.0193 (P: 0.0186 V: 0.0076 A: 0.0130 B: 0.0072)
Epoch 9 | Batch 750/1303 | Train Loss: 0.0194 (P: 0.0187 V: 0.0078 A: 0.0133 B: 0.0074)
Epoch 9 | Batch 800/1303 | Train Loss: 0.0182 (P: 0.0174 V: 0.0076 A: 0.0130 B: 0.0074)
Epoch 9 | Batch 850/1303 | Train Loss: 0.0174 (P: 0.0167 V: 0.0074 A: 0.0127 B: 0.0073)
Epoch 9 | Batch 900/1303 | Train Loss: 0.0179 (P: 0.0172 V: 0.0072 A: 0.0124 B: 0.0073)
Epoch 9 | Batch 950/1303 | Train Loss: 0.0186 (P: 0.0178 V: 0.0077 A: 0.0132 B: 0.0073)
Epoch 9 | Batch 1000/1303 | Train Loss: 0.0182 (P: 0.0174 V: 0.0074 A: 0.0126 B: 0.0073)
Epoch 9 | Batch 1050/1303 | Train Loss: 0.0183 (P: 0.0176 V: 0.0073 A: 0.0126 B: 0.0074)
Epoch 9 | Batch 1100/1303 | Train Loss: 0.0186 (P: 0.0179 V: 0.0073 A: 0.0124 B: 0.0073)
Epoch 9 | Batch 1150/1303 | Train Loss: 0.0175 (P: 0.0167 V: 0.0075 A: 0.0128 B: 0.0073)
Epoch 9 | Batch 1200/1303 | Train Loss: 0.0181 (P: 0.0174 V: 0.0072 A: 0.0123 B: 0.0073)
Epoch 9 | Batch 1250/1303 | Train Loss: 0.0180 (P: 0.0172 V: 0.0073 A: 0.0125 B: 0.0074)
Epoch 9 | Batch 1300/1303 | Train Loss: 0.0176 (P: 0.0169 V: 0.0070 A: 0.0119 B: 0.0073)
Epoch 9/10 | Avg Train Loss: 0.0186 (P: 0.0179 V: 0.0076 A: 0.0131 B: 0.0074)
Epoch 9 | Val Loss: 0.0207 MPJPE: 41.88mm (P: 0.0200 V: 0.0011 A: 0.0011 B: 0.0073)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_009_valloss_0.0207_mpjpe_41.88_B_0.0073.pth
Epoch 10 | Batch 0/1303 | Train Loss: 0.0185 (P: 0.0178 V: 0.0077 A: 0.0131 B: 0.0072)
Epoch 10 | Batch 50/1303 | Train Loss: 0.0176 (P: 0.0168 V: 0.0073 A: 0.0125 B: 0.0073)
Epoch 10 | Batch 100/1303 | Train Loss: 0.0185 (P: 0.0177 V: 0.0072 A: 0.0124 B: 0.0075)
Epoch 10 | Batch 150/1303 | Train Loss: 0.0175 (P: 0.0168 V: 0.0071 A: 0.0123 B: 0.0072)
Epoch 10 | Batch 200/1303 | Train Loss: 0.0185 (P: 0.0177 V: 0.0073 A: 0.0124 B: 0.0073)
Epoch 10 | Batch 250/1303 | Train Loss: 0.0175 (P: 0.0168 V: 0.0074 A: 0.0127 B: 0.0072)
Epoch 10 | Batch 300/1303 | Train Loss: 0.0178 (P: 0.0170 V: 0.0075 A: 0.0128 B: 0.0072)
Epoch 10 | Batch 350/1303 | Train Loss: 0.0167 (P: 0.0160 V: 0.0069 A: 0.0118 B: 0.0072)
Epoch 10 | Batch 400/1303 | Train Loss: 0.0176 (P: 0.0168 V: 0.0070 A: 0.0120 B: 0.0071)
Epoch 10 | Batch 450/1303 | Train Loss: 0.0186 (P: 0.0179 V: 0.0073 A: 0.0125 B: 0.0073)
Epoch 10 | Batch 500/1303 | Train Loss: 0.0193 (P: 0.0186 V: 0.0073 A: 0.0125 B: 0.0071)
Epoch 10 | Batch 550/1303 | Train Loss: 0.0171 (P: 0.0164 V: 0.0068 A: 0.0117 B: 0.0071)
Epoch 10 | Batch 600/1303 | Train Loss: 0.0177 (P: 0.0170 V: 0.0072 A: 0.0124 B: 0.0071)
Epoch 10 | Batch 650/1303 | Train Loss: 0.0175 (P: 0.0168 V: 0.0072 A: 0.0123 B: 0.0070)
Epoch 10 | Batch 700/1303 | Train Loss: 0.0184 (P: 0.0177 V: 0.0071 A: 0.0122 B: 0.0071)
Epoch 10 | Batch 750/1303 | Train Loss: 0.0191 (P: 0.0184 V: 0.0074 A: 0.0128 B: 0.0071)
Epoch 10 | Batch 800/1303 | Train Loss: 0.0168 (P: 0.0160 V: 0.0071 A: 0.0121 B: 0.0071)
Epoch 10 | Batch 850/1303 | Train Loss: 0.0170 (P: 0.0163 V: 0.0072 A: 0.0123 B: 0.0069)
Epoch 10 | Batch 900/1303 | Train Loss: 0.0173 (P: 0.0166 V: 0.0070 A: 0.0120 B: 0.0070)
Epoch 10 | Batch 950/1303 | Train Loss: 0.0164 (P: 0.0157 V: 0.0069 A: 0.0119 B: 0.0070)
Epoch 10 | Batch 1000/1303 | Train Loss: 0.0171 (P: 0.0164 V: 0.0072 A: 0.0124 B: 0.0070)
Epoch 10 | Batch 1050/1303 | Train Loss: 0.0178 (P: 0.0171 V: 0.0073 A: 0.0125 B: 0.0070)
Epoch 10 | Batch 1100/1303 | Train Loss: 0.0175 (P: 0.0168 V: 0.0071 A: 0.0122 B: 0.0069)
Epoch 10 | Batch 1150/1303 | Train Loss: 0.0173 (P: 0.0167 V: 0.0072 A: 0.0123 B: 0.0069)
Epoch 10 | Batch 1200/1303 | Train Loss: 0.0174 (P: 0.0166 V: 0.0072 A: 0.0123 B: 0.0071)
Epoch 10 | Batch 1250/1303 | Train Loss: 0.0164 (P: 0.0157 V: 0.0069 A: 0.0119 B: 0.0069)
Epoch 10 | Batch 1300/1303 | Train Loss: 0.0173 (P: 0.0166 V: 0.0072 A: 0.0124 B: 0.0069)
Epoch 10/10 | Avg Train Loss: 0.0178 (P: 0.0171 V: 0.0073 A: 0.0124 B: 0.0071)
Epoch 10 | Val Loss: 0.0203 MPJPE: 41.01mm (P: 0.0196 V: 0.0011 A: 0.0010 B: 0.0071)
Best model checkpoint saved to checkpoints/training_check\training_check_1\model_epoch_010_valloss_0.0203_mpjpe_41.01_B_0.0071.pth
Training finished for run: training_check_1
